1. Q: A developer writes this Rust code for a blockchain transaction pool: `let mut pending = Arc::new(HashMap::new()); thread::spawn(move || { pending.insert(tx_hash, tx); });` What is wrong and how to fix it?
   A: **Issue**: `Arc<HashMap>` provides shared ownership but not interior mutability. The code won't compile because `Arc` doesn't allow mutation without a lock. **Impact**: Compilation failure; even if it compiled with unsafe code, would cause data races in concurrent transaction insertion leading to undefined behavior and potential double-spending. **Correction**: Use `Arc<Mutex<HashMap<TxHash, Transaction>>>` or `Arc<RwLock<HashMap>>` for shared mutable state across threads: `let pending = Arc::new(Mutex::new(HashMap::new())); let pending_clone = Arc::clone(&pending); thread::spawn(move || { pending_clone.lock().unwrap().insert(tx_hash, tx); });`

1. Q: In Solana transaction processing, a program declares accounts as: `accounts: [signer, writable_account, writable_account]` but only reads from both writable accounts. What is wrong and how to fix it?
   A: **Issue**: Declaring accounts as writable when only reading them causes false account conflicts, preventing parallel execution of non-conflicting transactions. Sealevel runtime conservatively assumes write lock needed. **Impact**: Reduces parallelism by 40-60% for read-heavy workloads, directly lowering validator throughput and potentially missing block production deadlines. **Correction**: Declare read-only accounts explicitly: `accounts: [signer, readonly_account, readonly_account]` or in Anchor: `#[account(mut)]` only for accounts that will be modified. This allows runtime to schedule parallel execution of transactions reading same accounts.

1. Q: A smart contract uses `uint256 amount = balanceOf[sender] - value; balanceOf[sender] = amount;` to deduct tokens. What is wrong and how to fix it?
   A: **Issue**: Integer underflow vulnerability. If `value > balanceOf[sender]`, uint256 wraps around to 2^256 - (value - balance), crediting sender with massive unintended balance. **Impact**: Critical security vulnerability enabling theft of all contract funds. Exploited in multiple 2016-2017 token hacks before Solidity 0.8. **Correction**: Use Solidity 0.8+ with built-in overflow checks (reverts on underflow), or explicitly check: `require(balanceOf[sender] >= value, "Insufficient balance"); balanceOf[sender] -= value;` In Rust smart contracts, use checked arithmetic: `balance.checked_sub(value).ok_or(Error::InsufficientBalance)?`

1. Q: A DEX AMM swap function calculates output as: `output_amount = (input_amount * output_reserve) / input_reserve;` without applying fees. What is wrong and how to fix it?
   A: **Issue**: Violates constant product invariant x*y=k by not accounting for fees. After swap, `(input_reserve + input_amount) * (output_reserve - output_amount)` will be less than k, breaking the core AMM property. **Impact**: Pool value leaks with each trade, incentivizing arbitrage that drains pool reserves over time. Mathematical inconsistency causes price manipulation vulnerabilities. **Correction**: Apply fee before calculation: `let input_with_fee = input_amount * 997 / 1000; // 0.3% fee; let output_amount = (input_with_fee * output_reserve) / (input_reserve + input_with_fee);` This ensures new product `(input_reserve + input_amount) * (output_reserve - output_amount) >= k` (grows slightly due to fees).

1. Q: An event monitor processes Ethereum events with: `for block in last_processed..=current_block { process_events(block); }` What is wrong and how to fix it?
   A: **Issue**: No reorg handling. If blockchain reorganizes (uncle blocks), events from reverted blocks are already processed and won't be unwound, causing state inconsistencies. **Impact**: Duplicated/phantom events lead to incorrect balance calculations, missed reversals, and potential financial loss. Affects 1-3% of blocks during network instability. **Correction**: Add confirmation depth and reorg detection: `let confirmed_block = current_block.saturating_sub(12); if current_block < last_processed { handle_reorg(last_processed, current_block); } for block in last_processed..=confirmed_block { process_events(block); }` Store last 12 blocks in reversible buffer for reorg recovery.

1. Q: A cross-chain bridge validates transfers with: `if signatures.len() >= threshold { execute_transfer(); }` What is wrong and how to fix it?
   A: **Issue**: Count-based threshold without verifying signature validity or uniqueness. Malicious validator could submit same signature multiple times or invalid signatures to meet threshold. **Impact**: Critical security vulnerability allowing unauthorized bridge transfers and total loss of locked funds (multi-million dollar exploit risk). **Correction**: Verify each signature and ensure uniqueness: `let mut valid_signers = HashSet::new(); for sig in &signatures { let signer = recover_signer(transfer_hash, sig)?; require!(authorized_validators.contains(&signer), "Unauthorized"); require!(valid_signers.insert(signer), "Duplicate signature"); } require!(valid_signers.len() >= threshold, "Insufficient signatures");`

1. Q: Gas optimization code uses: `for (uint i; i < arr.length; i++) { process(arr[i]); }` What is wrong and how to fix it?
   A: **Issue**: `arr.length` is read from storage on every iteration, costing 100 gas per read. For 100-element array, wastes 10,000 gas unnecessarily. **Impact**: 30-50% higher gas costs for array operations, making protocol uncompetitive and limiting adoption. **Correction**: Cache length in memory: `uint256 len = arr.length; for (uint256 i; i < len; i++) { process(arr[i]); }` Saves 9,900 gas for 100-element array (1 storage read instead of 100). Further optimize with unchecked increment: `for (uint256 i; i < len;) { process(arr[i]); unchecked { ++i; } }` saves additional 5-10 gas per iteration in Solidity 0.8+.

1. Q: A Rust async function holds a mutex across await: `let data = mutex.lock().unwrap(); async_operation().await; drop(data);` What is wrong and how to fix it?
   A: **Issue**: Holding synchronous mutex guard across await point blocks executor thread, preventing other tasks from running. If async operation takes seconds, entire runtime stalls. **Impact**: Deadlocks or severe throughput degradation (10-100x slowdown) in async blockchain indexers, RPC servers, and validators. Violates async runtime assumptions. **Correction**: Use async-aware lock or minimize critical section: **Option 1**: `let data = { mutex.lock().unwrap().clone() }; async_operation().await;` (release lock before await) **Option 2**: Use `tokio::sync::Mutex`: `let data = async_mutex.lock().await; async_operation().await; drop(data);` (async-aware locking). Best practice: restructure to avoid holding locks across await entirely.

1. Q: A blockchain node checks transaction nonce with: `if tx.nonce == expected_nonce { apply_transaction(tx); expected_nonce++; }` in concurrent environment. What is wrong and how to fix it?
   A: **Issue**: Race condition (check-then-act pattern) allows multiple threads to pass the nonce check simultaneously, executing duplicate transactions. Time-of-check-time-of-use (TOCTOU) vulnerability. **Impact**: Double-spending if two threads process same transaction concurrently. Causes consensus failure and chain split if different validators execute different transaction sets. **Correction**: Use atomic compare-and-swap or lock critical section: `let mut account = accounts.entry(tx.sender).or_default(); if account.nonce != tx.nonce { return Err(Error::InvalidNonce); } apply_transaction(&tx, &mut account)?; account.nonce += 1;` Entire check-execute-increment sequence must be atomic. Better: use `Mutex` or `RwLock` to serialize per-account transaction processing.

1. Q: A developer optimizes storage by packing multiple values: `uint128 value1; uint128 value2;` in a struct, assuming they'll fit in one storage slot, but updates them separately: `data.value1 = new_value1;` and later `data.value2 = new_value2;` What is wrong and how to fix it?
   A: **Issue**: While both uint128 fit in one uint256 slot (good), updating them separately causes two SSTORE operations (20,000 gas each = 40,000 gas total) instead of one. Packing benefit wasted by unoptimized access pattern. **Impact**: Expected 50% gas savings from packing, but actual savings only 10-15% due to separate writes. Misleading optimization. **Correction**: Update both values simultaneously when possible: `data = Data { value1: new_value1, value2: new_value2 };` uses single SSTORE (20,000 gas = 50% savings). If values update independently, reconsider packing—separate uint256s with separate update patterns may be more gas-efficient despite using two slots. Measure actual gas with both approaches.

1. Q: An indexer queries Ethereum events with: `let events = contract.events().from_block(0).to_block(latest).query().await?;` What is wrong and how to fix it?
   A: **Issue**: Querying entire chain history (millions of blocks) in single RPC call will timeout or hit provider rate limits (most providers limit to 10,000 blocks per query). Also loads gigabytes of data into memory at once. **Impact**: Application crashes with OOM error or RPC timeouts; never successfully syncs. Development and testing can't detect issue on small testnets. **Correction**: Batch queries in chunks: `let chunk_size = 1000; for start_block in (0..=latest).step_by(chunk_size) { let end_block = (start_block + chunk_size).min(latest); let events = contract.events().from_block(start_block).to_block(end_block).query().await?; process_events(events).await?; save_progress(end_block).await?; }` Add progress checkpointing for crash recovery and respect provider rate limits with delays between chunks.

1. Q: A smart contract oracle updates price with: `latestPrice = fetchPrice(); emit PriceUpdated(latestPrice);` without validation. What is wrong and how to fix it?
   A: **Issue**: No staleness check, price reasonableness validation, or manipulation detection. Malicious/compromised oracle could inject extreme prices (0, max uint, 100x off-market) causing liquidations or arbitrage exploits. **Impact**: Flash loan attacks manipulate oracle source to trigger mass liquidations in lending protocols, stealing millions. Historical examples: bZx 2020 ($350k), Harvest Finance 2020 ($24M). **Correction**: Multi-layered validation: `uint256 newPrice = fetchPrice(); require(block.timestamp - lastUpdate >= MIN_UPDATE_INTERVAL, "Too frequent"); require(newPrice > 0 && newPrice <= MAX_REASONABLE_PRICE, "Invalid price"); uint256 change = newPrice > latestPrice ? newPrice - latestPrice : latestPrice - newPrice; require(change <= latestPrice / MAX_CHANGE_PERCENT, "Price changed too fast"); latestPrice = newPrice; lastUpdate = block.timestamp; emit PriceUpdated(newPrice);` Use Chainlink or Uniswap TWAP (time-weighted average) for manipulation resistance.

1. Q: A Rust program calculates median with: `let mut values = vec![...]; values.sort(); let median = values[values.len() / 2];` What is wrong and how to fix it?
   A: **Issue**: Integer division floors down, so for even-length vectors, always returns second-half element instead of average of two middle elements (standard median definition). Off-by-one bias. **Impact**: Systematic skew in blockchain gas price estimation, potentially causing 5-10% overpayment or transaction failures. Statistical incorrectness breaks assumptions in dependent systems. **Correction**: Handle odd/even cases: `values.sort_unstable(); let median = if values.len() % 2 == 1 { values[values.len() / 2] } else { let mid = values.len() / 2; (values[mid - 1] + values[mid]) / 2 };` For integer types, be careful with overflow in average calculation: `values[mid-1]/2 + values[mid]/2` or use checked arithmetic.

1. Q: A developer profiles Rust code and sees 30% CPU time in `keccak256()` calls, then optimizes by caching hashes: `let cache = Arc::new(Mutex<HashMap<Vec<u8>, Hash>>);` What is wrong and how to fix it?
   A: **Issue**: Using `Vec<u8>` as HashMap key requires cloning data on every lookup for hashing, negating cache benefits. Also mutex contention in hot path causes more overhead than original hash computation. **Impact**: Cache actually slows down code by 20-40% instead of speeding it up. Incorrect profiling interpretation leads to counter-productive optimization. **Correction**: Use borrowed key type or fixed-size array: `let cache: DashMap<[u8; 32], Hash> = DashMap::new();` (lock-free concurrent map with fixed-size key). Or restructure to cache by higher-level identifier (transaction hash) instead of raw data. Always benchmark "optimization" to confirm improvement; premature optimization is root of evil. Consider if SIMD-accelerated hash (`sha3` crate with AVX-512) would be simpler than caching.

1. Q: A cross-chain bridge implements retry logic: `while !transaction_confirmed() { submit_transaction(); sleep(1 sec); }` What is wrong and how to fix it?
   A: **Issue**: No idempotency check—if first transaction is pending (not failed), subsequent submits create duplicate transactions, executing bridge transfer multiple times and losing funds. **Impact**: Multiplies user funds loss; 2-10x overdraft depending on retry count. Catastrophic in production. Historical example: several bridges lost $10M+ from retry logic bugs. **Correction**: Generate deterministic transaction ID and check before retry: `let tx_id = generate_idempotent_id(&transfer); loop { match check_status(tx_id) { Status::Confirmed => return Ok(()), Status::Failed => { submit_transaction(tx_id, &transfer)?; sleep(backoff.next()); }, Status::Pending => sleep(poll_interval), } }` Use exponential backoff to avoid hammering network. Store processed tx_id in database to prevent double-processing across restarts.
