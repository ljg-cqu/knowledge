1. Q: An engineer implements MPC key generation with the following approach: "We'll store all key shards in a single database with AES-256 encryption. Each shard will be encrypted with the same master key for simplicity." What is wrong and how to fix it?
   A: **Issue**: Single point of failure - if the database and master key are compromised, all key shards are exposed, defeating the purpose of MPC. **Why**: MPC security relies on geographic and cryptographic distribution of shards so no single point holds enough information to reconstruct the private key. **Correction**: Implement multi-layer encryption where each shard is encrypted with a shard-specific key, which is then encrypted with a master key from an HSM. Distribute encrypted shards across multiple geographic regions (3+ regions with 2-of-3 quorum recovery).

1. Q: A developer writes: "For optimal performance, I'll cache precomputed nonces in memory without encryption since they're just random numbers." What is wrong and how to fix it?
   A: **Issue**: Nonce reuse vulnerability - unencrypted cached nonces can be exposed through memory dumps or side-channel attacks, and if reused across signatures, they can leak the private key in ECDSA/EdDSA schemes. **Why**: Nonce reuse in ECDSA allows private key extraction from just two signatures; unencrypted storage violates security assumptions. **Correction**: Store precomputed nonces in secure storage (encrypted with AES-256-GCM), use them only once, implement secure deletion after use, and maintain audit trail of nonce generation and consumption.

1. Q: An architect proposes: "We'll use a monolithic architecture for our multi-chain MPC wallet because it's simpler to build. We can add support for new blockchain protocols by adding more if-else statements in the signing module." What is wrong and how to fix it?
   A: **Issue**: High coupling and poor modularity - blockchain-specific code scattered throughout the codebase creates tight coupling, making it difficult to test, audit, and maintain as new chains are added. **Why**: Each new chain requires modifying core signing logic, increasing regression risk and making security audits more complex and expensive. **Correction**: Use hexagonal architecture with protocol-agnostic ports defining interfaces for signing operations. Implement chain-specific adapters (Ethereum, Bitcoin, Solana) that encapsulate blockchain details while the core domain logic remains unchanged when adding new chains.

1. Q: A team implements FROST signing ceremony with this timeout logic: "We'll use a fixed 5-second timeout for all network operations to keep things fast and responsive." What is wrong and how to fix it?
   A: **Issue**: Aggressive fixed timeout causes excessive false positives in degraded network conditions, wasting computational resources by aborting ceremonies that would have succeeded with slightly more time. **Why**: Network latency varies significantly across geographic regions and network conditions; a fixed low timeout doesn't account for p95/p99 latency spikes. **Correction**: Implement adaptive timeout based on network conditions - start at 10 seconds (p50 latency Ã— 2.5), exponentially back off to 30 seconds if network degradation detected, and use circuit breaker pattern to track per-party health scores rather than simple timeout.

1. Q: An engineer writes: "I'll implement the saga pattern for distributed signing by just retrying failed operations 3 times. If it fails after 3 retries, we abort." What is wrong and how to fix it?
   A: **Issue**: Missing compensation logic and partial state cleanup - simple retries don't address partially completed steps that need to be rolled back, leading to inconsistent state across participants. **Why**: Distributed signing involves multiple steps (nonce commitment, partial signature, aggregation); failure in step 2 requires compensating action to clean up step 1 state, not just retry. **Correction**: Implement proper saga pattern with compensating transactions for each step. Each step should have a corresponding rollback action: deregister participants, release shard locks, invalidate partial signatures, and ensure all parties agree on abort through cryptographically signed abort messages.

1. Q: A developer implements CQRS: "We'll update both the command store and query store in the same database transaction to ensure consistency." What is wrong and how to fix it?
   A: **Issue**: Defeats the purpose of CQRS and creates tight coupling between write and read models, losing the scalability benefits of separation. **Why**: CQRS value comes from allowing write and read models to scale independently and use different storage optimizations; synchronous dual-write creates a bottleneck. **Correction**: Write to command store (PostgreSQL for ACID) and propagate to query store (ClickHouse for analytics) asynchronously via CDC (Change Data Capture) streaming through Kafka. Accept eventual consistency with 20-40ms lag, monitor projection lag, and design queries to tolerate this delay.

1. Q: For MPC wallet security, a team decides: "We'll use GG18 protocol because it has more rounds (9) which means better security than FROST (2 rounds)." What is wrong and how to fix it?
   A: **Issue**: Misunderstanding of security vs. round count relationship - more rounds doesn't mean better security; both GG18 and FROST provide equivalent cryptographic security guarantees. **Why**: Security depends on cryptographic assumptions (discrete log problem) and fault tolerance (both tolerate t malicious parties in t-of-n setup), not round count. More rounds actually increase attack surface and latency. **Correction**: Choose protocol based on use case requirements: GG18/GG20 for ECDSA chains (Bitcoin/Ethereum) with proven UC-security, FROST for Schnorr/EdDSA chains (Solana) for lower latency. Both provide 128-bit+ security with proper implementation.

1. Q: An architect designs rate limiting: "We'll implement a global rate limit of 1000 requests/second across all users to protect our signing service." What is wrong and how to fix it?
   A: **Issue**: Unfair resource allocation - a few high-volume users can exhaust the global limit, causing denial of service for other legitimate users ("noisy neighbor" problem). **Why**: Global limits don't provide per-user fairness and can't distinguish between legitimate high-frequency traders and potential attackers. **Correction**: Implement per-device or per-wallet token bucket rate limiting (e.g., 10 rps per wallet with burst capacity of 20). Use adaptive rate limiting that adjusts based on behavioral analysis (request patterns, failure rates, geographic anomalies) and reserve capacity for premium users.

1. Q: A developer implements key shard recovery: "When recovering from backup, we'll retrieve all shards simultaneously from all regions to be fast." What is wrong and how to fix it?
   A: **Issue**: Violates threshold security principle - fetching all shards to a single location temporarily creates a single point of failure where the complete private key could be reconstructed. **Why**: MPC security model requires that no single location ever holds threshold number of unencrypted shards; simultaneous retrieval breaks this invariant. **Correction**: Implement threshold-based recovery ceremony where shards are used in place without central aggregation. Only t-of-n shards participate in distributed signature reconstruction protocol, and recovery requires multi-party approval with cryptographic proofs, maintaining split knowledge throughout.

1. Q: For multi-chain integration, a developer writes: "I'll implement a unified `sign(transaction)` method that auto-detects the chain type from the transaction format and applies the right signing logic internally." What is wrong and how to fix it?
   A: **Issue**: Hidden complexity and type safety violation - auto-detection adds error-prone logic and loses compile-time type checking for chain-specific requirements (e.g., EIP-1559 for Ethereum, recent blockhash for Solana). **Why**: Different chains have incompatible transaction structures and validation rules; auto-detection can fail silently or produce invalid signatures if format is ambiguous. **Correction**: Use explicit chain-specific adapters implementing a `ChainAdapter` interface with methods like `buildUnsignedTx()` and `broadcastSignedTx()`. Require caller to specify chain ID explicitly, use type-safe transaction builders for each chain, and validate chain-specific rules before signing.
