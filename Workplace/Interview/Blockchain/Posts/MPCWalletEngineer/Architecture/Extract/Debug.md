1. Q: An MPC wallet implementation stores all key shards in the same database table with the signing logic directly querying the database. What is wrong and how to fix it?
   A: **Issue**: Violates separation of concerns—cryptographic operations directly coupled to storage implementation. Single database is single point of failure (100% blast radius). No abstraction means changing storage backend requires modifying signing logic. **Impact**: Security audit must review entire codebase, cannot swap storage backends (e.g., migrate from database to HSM), testing requires real database (slow, brittle), blast radius is 100% if database compromised. **Correction**: Implement hexagonal architecture with `ShardStorage` port interface. Signing logic depends on interface, not concrete implementation. Multiple adapters (DatabaseAdapter, HSMAdapter, EncryptedFileAdapter) implement the port. Reduces coupling from 100% to <30%, enables independent testing with mock adapters, limits blast radius to compromised region (50-70% reduction in multi-region deployment).

1. Q: A saga orchestrator for MPC signing implements compensation by deleting partial signatures from memory. During a crash, corrupted partial signatures remain in the system. What is wrong and how to fix it?
   A: **Issue**: Non-persistent compensation state means crash recovery is incomplete. In-memory compensation is lost on orchestrator failure, leaving system in inconsistent state (some participants have cancelled, others waiting). Violates idempotency—restarting saga may re-execute steps already completed. **Impact**: 15-20% of ceremonies stuck in partial state after orchestrator crash, requiring manual cleanup. Key shares may be locked (participants thinking ceremony ongoing) while orchestrator restarted with no memory. Average recovery time: 2-4 hours instead of target <15 minutes. **Correction**: Implement event-sourced saga with persistent operation log. Each saga step writes (operation_id, step, status) to durable storage before execution. Compensation actions also logged. On crash recovery, orchestrator replays log, skips completed steps (idempotent), executes pending compensations. Add distributed lock (Redis/ZooKeeper) to prevent multiple orchestrators processing same saga during failover. Reduces stuck ceremonies to <2%, recovery time to <5 minutes.

1. Q: An MPC implementation uses a fixed 5-second timeout for all signing rounds across all networks (mobile 4G, WiFi, datacenter). What is wrong and how to fix it?
   A: **Issue**: Fixed timeout doesn't adapt to network conditions. 5 seconds too aggressive for mobile/satellite (3G/LTE with 100-500ms RTT), causing false positive circuit trips (30-40% unnecessary failures). Too conservative for datacenter (10ms RTT), adding unnecessary 4.99 seconds to error detection. Doesn't account for participant load variations (participant CPU saturated = slower crypto). **Impact**: Mobile users experience 35% signing failure rate (false positive timeouts), requiring retries that frustrate UX. Datacenter deployments waste 90% of timeout window before detecting real failures. Mixed environments have unpredictable behavior. **Correction**: Implement adaptive timeout based on: (1) measured RTT (track p95 latency per participant, set timeout = RTT * rounds * 3), (2) participant health score (recent success rate), (3) protocol complexity (GG20 vs. FROST have different compute requirements). Example: Mobile participant with 200ms p95 RTT, 3-round protocol → timeout = 200ms * 3 * 3 = 1.8 seconds. Datacenter with 10ms RTT → timeout = 90ms. Reduces false positives by 60-70%, improves failure detection speed by 10x.

1. Q: A CQRS implementation updates the read model synchronously after every write command, blocking the write response until read projection completes. What is wrong and how to fix it?
   A: **Issue**: Synchronous read model update defeats CQRS benefits—write latency now includes read denormalization cost (20-40ms), losing separation between command and query scalability. If read model database is slow/down, writes are blocked (coupling availability). Essentially reimplementing two-phase commit, getting none of CQRS advantages. **Impact**: Write latency increases from 50ms (pure command) to 90ms (command + projection). Under load, read database slow query locks writes, cascading to zero throughput. Loses 10x read performance benefit because reads still contend with writes on same latency path. **Correction**: Implement asynchronous event-driven projection. Write command emits event to message bus (Kafka/RabbitMQ), returns immediately. Separate read projection service consumes events, updates read models independently. Accept eventual consistency (20-40ms lag). For use cases requiring read-your-writes, return command result with version stamp, UI polls/subscribes to read model until version matches. Achieves <50ms write latency, 10x read throughput, independent scaling of read/write paths.

1. Q: An MPC wallet architect decides to use a single 5-of-7 threshold for all wallets across consumer ($100) and institutional ($10M) use cases. What is wrong and how to fix it?
   A: **Issue**: One-size-fits-all threshold ignores risk/convenience trade-off. Consumer wallets need convenience (2-of-3 adequate for $100-$10K), 5-of-7 creates UX friction (coordinating 5 devices for $20 coffee purchase). Institutional wallets need higher security (7-of-10 or 9-of-15), 5-of-7 provides insufficient defense against targeted attacks on high-value assets. Cost inefficiency—institutional pays same infrastructure cost as consumer despite 1000x value difference. **Impact**: Consumer adoption drops 40-60% due to poor UX ("why do I need 5 approvals?"). Institutional customers refuse to onboard due to insufficient security guarantees, regulatory concerns (AML requires stronger controls for >$10K). Average cost per transaction is inefficient (same 7-shard infrastructure for $10 and $10M transactions). **Correction**: Implement tiered threshold policy: (1) Consumer tier (<$10K assets): 2-of-3 threshold, mobile-first UX. (2) Premium tier ($10K-$1M): 3-of-5 threshold, optional hardware keys. (3) Institutional tier (>$1M): Customizable 5-of-7 to 9-of-15, mandatory HSM backing, compliance workflows. Tie threshold to asset value with automatic graduation (wallet exceeding $10K auto-prompts upgrade to 3-of-5). Improves consumer conversion by 50%, unlocks institutional market, reduces infrastructure waste by 60%.

1. Q: A circuit breaker implementation opens after 3 consecutive failures but never closes automatically, requiring manual operator intervention. What is wrong and how to fix it?
   A: **Issue**: Manual-only recovery violates availability requirements—operators unavailable at 2am, weekends. Circuit stays open for hours after transient issue resolves (network blip), unnecessarily blocking traffic. No automated testing of participant recovery. Increases Mean Time To Repair (MTTR) from target <5 minutes to actual 2-4 hours. **Impact**: False positive circuit trip during 2am UTC when team asleep results in 6-hour signing downtime, violating 99.9% SLA (allows 43 minutes/month downtime). Single network hiccup causes extended outage because circuit never tests if participant recovered. Emergency paging at night exhausts on-call engineers. **Correction**: Implement half-open state with automatic transition. After cooldown period (30-60 seconds), circuit enters half-open, allowing single test request. If test succeeds, close circuit (full traffic). If test fails, reopen, double cooldown (exponential backoff: 30s → 60s → 120s → max 10 minutes). Add health check endpoint for synthetic monitoring (test requests don't count toward user quota). Provide manual override for emergency scenarios. Reduces MTTR from hours to seconds for transient failures, maintains automatic recovery while allowing operator control. Achieves 99.95% availability vs. previous 99.5%.

1. Q: An MPC signing implementation stores presignatures in plaintext memory (RAM) for performance, invalidating them only after use. What is wrong and how to fix it?
   A: **Issue**: Plaintext presignatures in RAM are attack target—memory dump reveals partial signatures usable for forgery. No memory protection (encryption, secure pages) means OS swapping to disk exposes presignatures in page file. Delayed invalidation creates window where used presignatures could be replayed if attacker controls network. Violates principle of least privilege—entire process memory has access instead of isolated signing thread. **Impact**: Memory scraping malware can extract presignatures, enabling signature forgery without compromising key shares. Process crash dumps sent to logging systems contain presignatures. OS hibernation writes RAM to disk unencrypted. Regulatory compliance failure (PCI DSS requires cryptographic material protection in memory). **Correction**: (1) Use `zeroize` crate (Rust) or `SecureString` (C#) to overwrite presignature memory immediately after use. (2) Request OS memory locking (`mlock()` on Linux, `VirtualLock()` on Windows) to prevent swapping. (3) Isolate presignature pool in separate process with minimal privileges, using IPC (Unix socket) for signing thread to request presignatures. (4) Encrypt presignatures in RAM using per-process key derived from HSM. (5) Add memory scrubbing on crash (register signal handlers to clear sensitive memory). Reduces attack surface by 80%, achieves compliance, adds 2-5ms latency for decryption.

1. Q: A multi-chain MPC wallet codebase directly imports Ethereum, Bitcoin, and Solana libraries into the core signing module, using if/else to select chain-specific logic. What is wrong and how to fix it?
   A: **Issue**: Tight coupling between core and chain implementations—adding new chain requires modifying core signing logic (violation of Open/Closed Principle). Core must have dependencies on all chain SDKs simultaneously (30-50MB binary size, dependency conflicts between SDK versions). Chain-specific bugs can propagate to signing module (blast radius). Testing core requires all chain infrastructure (slow, expensive, fragile). Security audit must review all chain integrations, not just signing logic. **Impact**: Binary size bloat (150MB vs. 10MB minimal core), 4-6 week lead time to add new chain (core modifications, full regression testing). Dependency version conflicts (Solana SDK requires Rust 1.70, Ethereum SDK requires Rust 1.68). One chain's SDK vulnerability forces entire wallet redeployment. Integration testing requires running 3 blockchains locally (20-minute test suite). **Correction**: Implement strategy pattern with `ChainAdapter` interface defining `BuildTransaction`, `SignTransaction`, `BroadcastTransaction`. Core depends only on interface, not concrete chains. Each chain is separate plugin/module implementing interface. Chain adapters loaded dynamically or compiled as feature flags. Core binary is 10MB, chain plugins add 5-15MB each on demand. Adding new chain: implement interface (~200 LOC), no core changes. Testing: core uses mock adapter (<1 second tests), chain adapters tested independently. Reduces coupling from 100% to 5%, deployment risk from global to per-chain, adds 10-15ms plugin invocation overhead.

1. Q: An MPC key generation ceremony uses sequential generation—participant 1 generates share 1, then participant 2 generates share 2, etc. What is wrong and how to fix it?
   A: **Issue**: Sequential execution means total time is sum of all participants (P1: 2s, P2: 2s, P3: 2s = 6s total), violating <5s target. Single slow participant blocks entire ceremony. Reveals ceremony progress to network observer (timing analysis). If P2 fails after P1 completes, P1's work wasted, ceremony restarts from scratch (O(n²) retry behavior). Trust model is broken—P1 could observe P2's generation before creating own share (selective abort attack). **Impact**: Key generation takes 6-10 seconds for 3-of-5 threshold (poor UX). 30% failure rate because single participant timeout aborts entire ceremony. Adversary monitoring network can infer ceremony state from timing patterns. Expected retry time after failure: 12-20 seconds (ceremony restart + retry), violating <15s recovery target. **Correction**: Implement parallel ceremony with cryptographic commitment phase. (Phase 1) All participants generate commitments simultaneously, broadcast within 2 seconds. (Phase 2) After collecting all commitments, participants generate shares in parallel, reveal within 2 seconds. Use verifiable secret sharing (VSS) so each share is cryptographically tied to commitment, preventing selective abort. Total time: max(P1, P2, P3) = 2s instead of sum. On failure, only failed participant retries (not full restart), recovery time <5 seconds. Parallel generation with timeout circuit breaker achieves 95%+ success rate on first attempt. Reduces keygen time from 6-10s to 2-3s, improves reliability from 70% to 97%.

1. Q: A wallet architecture stores encrypted key shards in a database with application-level encryption using a master key hardcoded in the source code. What is wrong and how to fix it?
   A: **Issue**: Hardcoded master key in source code is accessible to anyone with repository access (developers, CI/CD, source control breach). Application-level encryption means key is in process memory (vulnerable to memory dump). Single master key means all shards are protected by same secret—compromise = total loss. Key rotation requires re-encrypting all shards and redeploying application (downtime). Violates cryptographic best practice (keys should be hardware-protected, never in code). **Impact**: Developer laptop compromise exposes master key, enabling decryption of all user key shards (millions of wallets compromised from single breach). Source code repository leak (accidental public commit, contractor access) reveals key. Memory scraping malware extracts key from running process. Key rotation requires: (1) service downtime, (2) decrypt all shards with old key, (3) re-encrypt with new key, (4) redeploy—impossible at scale. Regulatory compliance failure (PCI DSS, SOC2 require hardware key protection). **Correction**: (1) Use Hardware Security Module (HSM) or cloud KMS (AWS KMS, GCP Cloud KMS) to store master key, never in code. (2) Implement envelope encryption: each shard has unique data encryption key (DEK), DEKs encrypted by HSM-stored key encryption key (KEK). (3) Retrieve KEK at runtime via authenticated API call with audit logging. (4) Rotate KEKs periodically (90 days) without re-encrypting shards (only DEK ciphertext updated). (5) Use separate KEKs per region/environment (dev/staging/prod). Reduces key exposure from "everyone with code access" to "authenticated HSM API calls with audit trail", enables zero-downtime rotation, achieves compliance. Cost: $1-5 per 10K API calls (acceptable for <100 calls/second).

1. Q: An event sourcing implementation stores events in a single append-only table with sequential integer IDs. Event replay loads all events into memory before processing. What is wrong and how to fix it?
   A: **Issue**: Single table becomes performance bottleneck—scanning millions of events for single wallet is O(n). Loading all events into memory causes out-of-memory crashes when event log exceeds RAM (typically 5-10M events = 50-100GB). Sequential IDs create hotspot in database (all writes to same index page), limiting throughput to ~5K events/second on single instance. No snapshotting means cold start (system reboot, new read model) requires replaying entire history (10M events = 30-60 minutes). Query by entity requires full table scan unless secondary index (adds write overhead). **Impact**: Wallet with 100K transactions takes 30 seconds to load (scanning 100K events). System with 10M total events cannot fit in 32GB RAM, crashes during replay. Write throughput limited to 5K events/s instead of target 100K. Adding new read model requires 1-hour replay of full history (blocks release). Cold start after database failover takes 45 minutes (downtime violation). **Correction**: (1) Partition events by aggregate ID (wallet ID)—each wallet's events in separate partition, enables parallel processing. (2) Implement snapshotting—store aggregate state snapshot every N events (e.g., every 100), replay only recent events. (3) Use UUIDs or composite keys (aggregate_id + timestamp) instead of sequential IDs, distributing writes across index. (4) Stream processing—read models consume events from message bus (Kafka) without loading to memory. (5) Implement event archival—move events older than 90 days to cold storage (S3), keeping hot store small. Achieves: wallet loading <100ms (snapshot + recent events), write throughput >50K events/s (partitioned writes), cold start <5 minutes (replay from recent snapshots), memory usage <8GB (no full history loading).
