1. Q: Your MPC wallet currently uses GG20 for threshold ECDSA signing with average latency of 300ms (p95). Mobile users are complaining about slow transaction signing. You're considering switching to FROST to reduce latency to ~120ms, but your security team is concerned about changing from a well-audited protocol. What would you do and why?
   A: **Decision**: Implement a hybrid approach with gradual migration. **Rationale**: (1) Deploy FROST adapter alongside existing GG20 using hexagonal architecture, allowing both protocols to coexist. (2) Start with 5% of retail wallets on FROST (low-value transactions) while keeping institutional custody on GG20. (3) Run both protocols in parallel for 3 months monitoring security incidents and latency improvements. (4) Both protocols provide equivalent security (2 malicious node tolerance, 128-bit security) but FROST achieves 60% latency reduction critical for mobile UX. (5) If no security issues after 3 months and user satisfaction improves, gradually migrate remaining wallets. **Trade-offs**: Temporary operational complexity of dual protocols (+15% maintenance overhead) vs. improved user retention from better UX (reduced latency directly impacts mobile wallet adoption).

1. Q: You're designing key shard storage for a multi-region MPC wallet deployment. Option A: Store shards in 3 regions with 2-of-3 recovery using DynamoDB Global Tables (simple, managed, $800/month). Option B: Implement custom CQRS with event sourcing using PostgreSQL + ClickHouse ($400/month but requires 2 engineers to maintain). Your system handles 50K wallets with compliance requirements for audit trails. What would you do and why?
   A: **Decision**: Choose CQRS with event sourcing (Option B) despite higher operational complexity. **Rationale**: (1) Compliance requirements for audit trails are non-negotiable - event sourcing provides immutable, complete history of all shard operations required for SOC2/ISO 27001. (2) DynamoDB Global Tables provide distribution but lack built-in audit trail and temporal query capabilities needed for forensic analysis. (3) CQRS enables read scalability for audit queries without impacting write-path performance of signing operations. (4) Initial engineering cost (2 engineers × 3 months = ~$50K) is justified by avoiding compliance violations and supporting future growth beyond 50K wallets. (5) Projection lag of 20-40ms is acceptable for audit queries (not real-time requirement). **Trade-offs**: Higher upfront development cost and operational complexity vs. regulatory compliance, auditability, and long-term scalability benefits.

1. Q: Your distributed signing ceremony fails 15% of the time due to participant timeouts in cross-region deployments (US-EU-ASIA). You can: (A) Increase timeout from 10s to 30s (reduces failures but increases user wait time), (B) Implement circuit breaker with adaptive timeouts and per-party health scoring (complex but intelligent), or (C) Reduce participant count from 5 to 3 (faster but lower fault tolerance). What would you do and why?
   A: **Decision**: Implement circuit breaker with adaptive timeouts (Option B). **Rationale**: (1) Static 30s timeout (Option A) reduces failures but creates poor UX with 3× latency increase, unacceptable for mobile wallets. (2) Reducing to 3 participants (Option C) decreases fault tolerance from 2 malicious nodes to 1, unacceptable security degradation for custody systems. (3) Adaptive circuit breaker starts at 10s (p50 latency × 2.5), only extends to 30s when network degradation detected, providing best of both worlds. (4) Per-party health scoring (based on message response rate, proof validity, latency) enables early detection of problematic participants, allowing ceremony to proceed with backup participants. (5) Expected outcome: reduce failures from 15% to 3-4% while maintaining p95 latency <250ms. **Trade-offs**: Implementation complexity (~2 weeks development) vs. 75-80% failure reduction and maintained low latency for good network conditions.

1. Q: You're integrating your MPC wallet with 5 blockchain networks (Ethereum, Bitcoin, Solana, Polygon, Arbitrum). You can: (A) Build a monolithic service with chain-specific if-else logic (fast to build, 3 weeks), (B) Use hexagonal architecture with chain adapters (6 weeks but modular), or (C) Build separate microservices per chain (maximum isolation but 12 weeks and high ops cost). Your team is 3 engineers, expecting to add 3 more chains next quarter. What would you do and why?
   A: **Decision**: Use hexagonal architecture with chain adapters (Option B). **Rationale**: (1) Monolithic approach (Option A) creates 3 weeks of technical debt that becomes exponentially harder to refactor as more chains are added - each new chain requires touching core signing logic, increasing regression risk. (2) Microservices per chain (Option C) over-engineers for current scale; 5 chains don't justify operational overhead of 5+ services (deployment, monitoring, inter-service communication adds 50ms+ latency). (3) Hexagonal architecture provides the right abstraction: core MPC logic is chain-agnostic, chain-specific details (transaction encoding, RPC calls) isolated in adapters. (4) With 3 more chains coming next quarter, adapter pattern reduces integration time from 4 weeks (monolith) to <1 week (new adapter implementation). (5) Testing benefits: mock adapters enable fast unit tests, reducing test execution from minutes to seconds. **Trade-offs**: 2× initial development time (6 weeks vs 3 weeks) vs. 70-80% faster future chain additions and maintainable security audit surface.

1. Q: Your MPC signing API is receiving 5K requests/second with 20% coming from suspected bot attacks. Current system has no rate limiting and p99 latency is degrading to 800ms (target: <150ms). You can: (A) Add global rate limit 3K rps (simple, 1 day), (B) Implement per-wallet token bucket with behavioral analysis (complex, 2 weeks), or (C) Add captcha/proof-of-work for all requests (stops bots but adds friction). What would you do and why?
   A: **Decision**: Implement per-wallet token bucket with behavioral analysis (Option B) with temporary global rate limit during development. **Rationale**: (1) Deploy global 3K rps limit immediately as emergency measure to restore p99 latency to <200ms, buying time for proper solution. (2) Global limit (Option A) as permanent solution causes "noisy neighbor" problem - legitimate high-frequency traders blocked by bot traffic. (3) Captcha (Option C) breaks API integration for automated trading bots (legitimate use case) and adds unacceptable UX friction for mobile wallets. (4) Per-wallet token bucket (10 rps base, 20 burst) provides fairness while behavioral analysis (IP geolocation, request pattern entropy, error rates) identifies attackers. (5) Attackers showing >20% error rate trigger IP-level blocking via eBPF XDP for <10ms penalty. (6) Expected outcome: reduce malicious traffic by 95%, restore p99 latency to <150ms, maintain legitimate user access. **Trade-offs**: 2 weeks development + $300/month Redis cluster cost vs. eliminating 95% of bot attacks and enabling legitimate high-frequency use cases.

1. Q: Your MPC wallet needs to support both mobile SDK and backend service integration. You can: (A) Expose REST API only (universal, simple docs, easy debugging), (B) gRPC only (efficient binary protocol, streaming, but harder browser support), or (C) Hybrid REST gateway with internal gRPC (best of both but operational complexity). Clients include mobile apps (100K users), exchange integrations (10 partners), and web wallet (50K users). What would you do and why?
   A: **Decision**: Hybrid approach - public REST gateway with internal gRPC (Option C). **Rationale**: (1) Mobile and backend SDKs use gRPC directly for efficiency - binary protobuf reduces payload size by 30-40%, streaming enables real-time signing progress, strong typing from .proto definitions. (2) Web browsers and external partners use REST endpoint translated by envoy/grpc-gateway - adds 2-5ms translation overhead but enables cache-friendly HTTP, simple curl debugging, OpenAPI documentation. (3) Single source of truth (.proto files) generates both gRPC services and REST endpoints, reducing API drift. (4) Internal services benefit from gRPC features: deadlines, backpressure, bidi streaming for MPC ceremony coordination. (5) Measured improvement: 20-40% latency reduction for gRPC clients, 2-4× throughput for small messages, while maintaining REST compatibility for 10 exchange partners requiring standard HTTP. **Trade-offs**: One additional infrastructure hop for REST clients (+2-5ms) and gateway maintenance complexity vs. enabling high-performance native integrations for mobile/backend while preserving universal REST access.

1. Q: For disaster recovery, you need to decide on RPO (Recovery Point Objective) and RTO (Recovery Time Objective) for your MPC wallet storing $50M in custody. Option A: RPO=5min, RTO=30min using continuous replication ($2K/month). Option B: RPO=0, RTO=15min using synchronous multi-region writes ($5K/month). Option C: RPO=1hour, RTO=4hour using daily backups ($500/month). What would you do and why?
   A: **Decision**: Option B (RPO=0, RTO=15min) despite 2.5× cost increase. **Rationale**: (1) For $50M AUM custody, even 5 minutes of data loss (Option A) could mean dozens of unrecoverable signing operations worth $100K-500K if disaster strikes during high-volume trading. (2) RPO=0 is critical for institutional custody where clients expect zero transaction loss - any data loss creates liability and reputation damage far exceeding $3K/month cost difference. (3) RTO=15min (vs 30min) halves downtime cost: at $50M AUM, even 15 minutes of service unavailability could cost $50K-100K in missed trading opportunities and client trust. (4) Synchronous multi-region writes ensure geographic distribution of key shards with strong consistency, supporting 99.99% availability SLA. (5) Option C is unacceptable - 1 hour data loss and 4 hour downtime violates basic custody standards and would fail institutional client audits. **Trade-offs**: $60K/year additional infrastructure cost vs. eliminating data loss risk, meeting institutional SLAs, and supporting compliance requirements (SOC2 typically requires RPO<5min for critical financial data).

1. Q: Your team is implementing a new MPC wallet and must choose between CQRS+Event Sourcing (higher complexity, auditability) vs. traditional CRUD with read replicas (simpler, faster to build). You have 3 months to launch, 4 engineers, and compliance requirements for maintaining 7-year audit trail of all signing operations. What would you do and why?
   A: **Decision**: CQRS + Event Sourcing despite initial complexity. **Rationale**: (1) Audit trail is non-negotiable for compliance (SOC2, ISO 27001) - event sourcing provides immutable append-only log that auditors can verify, while CRUD databases can have data modified/deleted. (2) 7-year retention: event store naturally supports temporal queries ("show all signatures between 2023-2024") without complex backup management. (3) Technical debt cost: building CRUD initially means complete rewrite later for compliance - migration from CRUD to event sourcing while maintaining consistency is harder than building event-sourced from start. (4) Timeline: with 4 engineers and 3 months, allocate 2 engineers to event store infrastructure (using EventStoreDB or PostgreSQL + Debezium), 2 engineers to business logic. First month focuses on write path, second month on projections, third month on integration. (5) Performance: event append has 3ms latency, projections have 20-40ms lag (acceptable for audit queries). **Trade-offs**: 30% longer initial development vs. avoiding costly rewrite for compliance, built-in auditability, and ability to replay events for debugging production issues.

1. Q: You discover that precomputing nonces for faster signing could reduce latency by 60% (200ms → 80ms) but requires storing 2-3MB of encrypted nonces per wallet. With 100K wallets, this means 200-300GB additional storage ($1.5K/month). Security team is concerned about nonce storage risks. What would you do and why?
   A: **Decision**: Implement selective precomputation with risk-based tiers. **Rationale**: (1) Tier 1 (high-frequency retail, 30% of wallets): Enable full precomputation - these users make multiple transactions daily, 60% latency reduction significantly improves UX and reduces mobile battery drain. (2) Tier 2 (medium-frequency, 50% of wallets): Precompute 10 nonces (200KB per wallet) - balances performance improvement with storage cost, sufficient for daily transaction bursts. (3) Tier 3 (cold wallets, 20% of wallets): On-demand signing only - infrequent use doesn't justify storage cost. (4) Mitigation for security concerns: encrypt nonces with AES-256-GCM using per-wallet keys, store in HSM-backed key storage, implement automatic expiry (24-hour TTL), audit trail of nonce generation/consumption. (5) Cost optimization: tiered approach reduces storage to ~100GB ($750/month) while delivering latency improvements for 80% of active users. **Trade-offs**: $750/month storage cost and increased complexity vs. significantly improved mobile UX for majority of users, while maintaining security through encryption and strict nonce management.

1. Q: You're experiencing 5% failure rate in 5-party MPC signing ceremonies due to one chronically slow participant (geographic latency from APAC region). You can: (A) Remove APAC participant and go to 4-party (reduces latency but lowers fault tolerance), (B) Implement backup participants and failover logic (complex), or (C) Optimize network with dedicated VPN/VPC peering (costly). All participants are co-equal business partners. What would you do and why?
   A: **Decision**: Implement backup participants with smart failover (Option B). **Rationale**: (1) Cannot remove APAC participant (Option A) - business requirement for geographic distribution and co-equal partners means all regions must participate; reducing to 4 parties also lowers Byzantine fault tolerance. (2) Dedicated VPN (Option C) helps but doesn't solve fundamental geographic latency (APAC-US: 150-200ms minimum) and costs $2K-3K/month ongoing. (3) Backup participant design: Primary ceremony uses fastest 5 participants; if APAC node's health score drops below 0.6 for 2 consecutive rounds, circuit breaker triggers failover to designated backup in same region. (4) Backup nodes maintain "warm standby" - receive all broadcast messages but don't actively participate unless primary fails, adding minimal overhead. (5) Expected outcome: reduce failure rate from 5% to <1% by having fallback option while maintaining geographic distribution and fault tolerance. **Trade-offs**: Implementation complexity (~3 weeks) and 20% increased infrastructure cost (backup nodes) vs. 80% failure reduction and maintaining business requirements for multi-region participation.
