# Case Study / Scenario - Product Manager

Framework for generating high-quality product case study/scenario assessments with proper structure, citations, and multi-dimensional evaluation.

---

# Part I: Specifications

Define quality requirements, standards, and constraints.

## Specifications

### Scope and Structure

- **Scope**: 16–22 scenarios for senior/director/VP level Product Managers
- **Difficulty Distribution**: Maintain 20/40/40 balance (Foundational/Intermediate/Advanced)
- **Context**: 200–400 words with market constraints, stakeholders, user data, business metrics
- **Tasks**: 3–4 MECE tasks per scenario
- **Deliverables**: Product briefs (≤300 words), prioritization matrices, roadmap proposals, stakeholder memos, decision frameworks, go-to-market plans
- **Trade-offs**: User value vs revenue, short-term vs long-term, build vs buy vs partner, feature breadth vs depth, acquisition vs retention
- **Grading**: Partial-credit checklists; document product judgment, omissions, alternative approaches
- **Conflict Handling**: Solutions acknowledge competing frameworks; clarify where PM community agrees vs disagrees on prioritization/strategy approaches

### Citation Standards

- **Languages**: ~60% EN, ~30% ZH, ~10% other (tag each: [EN], [ZH], etc.)
- **Source Types**: (1) Product frameworks (RICE, AARRR, JTBD, OKR); (2) Research & data (market analyses, user research, case studies); (3) PM literature (books, articles, documented launches); (4) Tools & platforms (analytics, roadmapping, research tools)
- **Format**: APA 7th with language tags
- **Distribution**: Product Tools/Platforms; PM Literature/Case Studies
- **Inline Citation**: Use [Ref: ID] in context descriptions and rationales when referencing frameworks, market data, user insights, metrics, best practices. Narrative/connective sentences may remain uncited.

### Reference Minimum Requirements

| Section | Floor | Content |
|---------|-------|---------|
| Glossary | ≥10 | RICE, AARRR, JTBD, North Star, PMF, OKR, PLG, OST, etc. |
| Tools | ≥5 | Analytics, roadmapping, research platforms, collaboration |
| Literature | ≥6 | PM frameworks, market analyses, launches, case studies |
| Citations | ≥12 | ~60% EN / ~30% ZH / ~10% other (APA 7th with tags) |

**Exception**: If floor unmet, state shortfall + rationale + sourcing plan.

### Quality Gates

- **Recency**: ≥50% citations from last 3 years (≥70% for AI/platform domains)
- **Diversity**: ≥3 source types; no single source >25%
- **Evidence**: ≥70% scenarios have ≥1 citation; ≥30% have ≥2 citations
- **Tool Details**: Pricing, user base, last update ≤18 months, key integrations
- **Links**: Validate accessibility; use DOIs/archived URLs
- **Cross-refs**: All [Ref: ID] resolve to entries

> Scaling: For >25 scenarios, increase floors by ~1.5×. Prioritize gates before raising floors.

### Pre-Submission Validation

Execute ALL steps below. Present results in validation report table. Fix failures and re-run until all pass.

**Step 1 – Counts**: Glossary ≥10, Tools ≥5, Literature ≥6, APA ≥12, Scenarios 16-22 (20/40/40)

**Step 2 – Citations**: ≥70% scenarios have ≥1; ≥30% have ≥2

**Step 3 – Language**: EN 50-70%, ZH 20-40%, Other 5-15%

**Step 4 – Recency**: ≥50% from last 3 years (≥70% for AI/platform)

**Step 5 – Diversity**: ≥3 source types; no single >25%

**Step 6 – Links**: All accessible or archived

**Step 7 – Cross-refs**: All [Ref: ID] resolve (G#/T#/L#/A#)

**Step 8 – Context Length**: Sample 5 scenarios; all 200-400 words

**Step 9 – MECE Tasks**: All scenarios have non-overlapping, complete tasks

**Step 10 – Rubrics**: All scenarios have complete grading rubrics with point allocations

**Step 11 – Product Focus**: ≥80% scenarios test product judgment vs recall

**Validation Report Template:**
```
| Check | Result | Status |
|-------|--------|--------|
| Floors | G:X T:Y L:Z A:W S:N (F/I/A) | PASS/FAIL |
| Citation coverage | X% ≥1, Y% ≥2 | PASS/FAIL |
| Language dist | EN:X% ZH:Y% Other:Z% | PASS/FAIL |
| Recency | X% last 3yr | PASS/FAIL |
| Source diversity | N types, max P% | PASS/FAIL |
| Links | Y/X accessible | PASS/FAIL |
| Cross-refs | Y/X resolved | PASS/FAIL |
| Context lengths | 5/5 compliant | PASS/FAIL |
| MECE tasks | Y/X verified | PASS/FAIL |
| Grading rubrics | Y/X complete | PASS/FAIL |
| Product judgment | X% judgment-based | PASS/FAIL |
```

> **MANDATORY:** If ANY check shows FAIL, stop, fix issues, regenerate, and re-run validation. Only proceed when ALL checks show PASS.

### Submission Checklist

- [ ] All 11 validation steps PASS (see report table above)
- [ ] ALL reference floors met + quality gates passed

---

# Part II: Instructions

Execute generation workflow with inline quality checks at each step.

## Instructions

Follow these steps in order. Execute inline quality checks at each step before proceeding.

### Step 1: Topic Identification & Planning
1. Identify 4-6 PM clusters: Product Strategy | Discovery & Validation | Prioritization & Roadmapping | Metrics & Growth | Stakeholder Management | Go-to-Market
2. Allocate 3-4 scenarios per cluster (total 16-22)
3. Assign difficulty levels ensuring 20/40/40 balance
4. **Check**: Total = 16-22, ratio ≈20/40/40

### Step 2: Reference Collection
1. **Glossary (≥10)**: RICE, AARRR, JTBD, North Star, PMF, OKR, Continuous Discovery, PLG, Feature Factory, OST
2. **Tools (≥5)**: Mixpanel/Amplitude (analytics), ProductBoard/Aha! (roadmapping), Dovetail/UserTesting (research), Miro (collaboration)
3. **Literature (≥6)**: Cagan, Olsen, Torres, Perri, Patton, Klement + ZH sources (俞军, 梁宁, 苏杰)
4. **Citations (≥12)**: Tag language, year, type (1-4); assign IDs (G#/T#/L#/A#)
5. **Check**: Counts, language ~60/30/10%, recency ≥50% last 3yr, ≥3 types

### Step 3: Scenario Generation
1. For EACH scenario: Write context (200-400 words with market/user/business data)
2. Include ≥1 [Ref: ID] per context after data, frameworks, metrics
3. Design 3-4 MECE tasks with rubrics
4. **Check**: Every 3 scenarios verify lengths, citations, MECE tasks, rubrics

### Step 4: Grading Framework
1. For EACH task: Define expected product thinking, rubrics with partial credit
2. Document common product judgment gaps and exemplary approaches
3. **Check**: All tasks have rubrics? Points allocated?

### Step 5: References
1. Populate Glossary/Tools/Literature/APA with required fields
2. **Check**: All [Ref: ID] resolve

### Step 6: Validation
Execute all 11 steps (Part I). Fix failures; re-validate until all PASS.

### Step 7: Final Review
Check submission checklist. Submit when all PASS.

---

# Part III: Output Format

Template structure for generated scenario banks.

## Output Format

Use this structure when generating scenario banks:

```markdown
## Contents

- [Scenario Bank](#scenario-bank-scenarios-1-n)
- [Scenario 1: [Title]](#scenario-1-title)
- [Scenario 2: [Title]](#scenario-2-title)
- [Reference Sections](#reference-sections)
  - [Glossary, Terminology & Acronyms](#glossary-terminology--acronyms)
  - [Product Tools & Platforms](#product-tools--platforms)
  - [Authoritative Literature & Case Studies](#authoritative-literature--case-studies)
  - [APA Style Source Citations](#apa-style-source-citations)

---

## Scenario Bank (Scenarios 1–N)

### Scenario X: [Title]

**Difficulty:** [Foundational/Intermediate/Advanced] | **Domain:** [Strategy/Discovery/Prioritization/Metrics/Stakeholder/GTM]

**Context:** (200–400 words with market constraints, user data, stakeholders, business metrics; include [Ref: ID] citations)

[Scenario description with specific numbers, user feedback, competitive landscape, resource constraints]

**Task 1: Problem Diagnosis & Framework Application (8 pts)**
Identify the core product challenge and apply an appropriate framework (RICE, JTBD, North Star, etc.) to analyze the situation.

**Expected Response:** 
- Core problem identification (user pain/market gap/strategic misalignment)
- Framework selection with rationale
- Application of framework to scenario data
- Key insights from analysis

**Grading:**
- Problem identification: 2 pts (clear root cause vs symptom)
- Framework selection: 2 pts (appropriate for context)
- Framework application: 3 pts (correct use with scenario data)
- Insights: 1 pt (actionable conclusions)

**Task 2: Prioritization & Decision Matrix (10 pts)**
Create a decision framework to evaluate options. Consider trade-offs and recommend a path forward.

**Expected Response:**
- Decision criteria relevant to business context
- Weighted scoring or comparison matrix
- Evaluation of 2-3 options
- Clear recommendation with rationale

**Grading:**
- Criteria selection: 3 pts (relevant, measurable)
- Matrix construction: 3 pts (proper weighting/scoring)
- Option evaluation: 2 pts (thorough, objective)
- Recommendation: 2 pts (clear, justified)

**Task 3: Stakeholder Communication (6 pts)**
Draft a memo (≤300 words) communicating the decision to key stakeholders.

**Expected Response:**
- Executive summary of situation
- Recommendation with supporting data
- Addressed concerns/objections
- Next steps with timeline

**Grading:**
- Clarity: 2 pts (concise, structured)
- Data support: 2 pts (metrics, evidence)
- Stakeholder awareness: 1 pt (addresses concerns)
- Actionability: 1 pt (clear next steps)

**Common Product Judgment Gaps:**
- Choosing frameworks without considering context fit
- Ignoring opportunity costs in recommendations
- Failing to quantify user/business impact
- Not addressing execution feasibility
- Overlooking stakeholder concerns

**Exemplary Approaches for Bonus:**
- Proactively identifying risks and mitigation strategies (+2 pts)
- Proposing experiments/validation before full commitment (+2 pts)
- Including success metrics and monitoring plan (+1 pt)

---

## Reference Sections

Assign Reference IDs and reuse them inline in scenario contexts: Glossary (G1…Gn), Tools (T1…Tn), Literature (L1…Ln), APA Citations (A1…An). Example inline: [Ref: G2, T3, A5].

### Glossary, Terminology & Acronyms

**G1. AARRR (Pirate Metrics)**  
Acquisition → Activation → Retention → Referral → Revenue framework for tracking growth across customer lifecycle. Used for SaaS metrics, funnel optimization. Related: HEART, North Star Metric

**G2. RICE Prioritization**  
Reach × Impact × Confidence ÷ Effort scoring for feature prioritization. Used for roadmap planning, backlog ranking. Related: ICE, Value/Effort Matrix, KANO

**G3. Jobs-to-be-Done (JTBD)**  
Framework for understanding the underlying "job" users hire a product to accomplish (vs demographics). Used for feature ideation, segmentation, competitive analysis. Related: Outcome-driven innovation

**G4. North Star Metric**  
Single metric capturing core product value; leading indicator of sustainable growth. Used for company alignment, PLG, OKRs. Related: OMTM, Input/Output metrics

**G5. Product-Market Fit (PMF)**  
Degree product satisfies market demand; measured when retention flattens and organic growth accelerates. Used for validation, pivot decisions, expansion. Related: Problem-solution fit, MVP

**G6. OKR (Objectives and Key Results)**  
Goal framework where Objectives = what to achieve, Key Results = how to measure. Used for quarterly planning, cross-functional alignment. Related: KPI, North Star, V2MOM

**G7. Continuous Discovery**  
Regular customer engagement through structured interviews/testing to inform decisions (vs periodic projects). Used for weekly interviews, opportunity trees, assumption testing. Related: Dual-track agile, Build-Measure-Learn

**G8. Product-Led Growth (PLG)**  
GTM strategy where product drives acquisition, conversion, expansion (vs sales-led). Used for SaaS freemium, self-serve onboarding, viral loops. Related: PQLs, Time-to-Value, Expansion revenue

**G9. Feature Factory**  
Anti-pattern: shipping features (outputs) vs solving problems (outcomes). Used in transformation discussions, outcome-based PM. Related: Build trap, Empowered teams

**G10. Opportunity Solution Tree (OST)**  
Visual framework mapping outcomes → opportunities (needs/pains) → solutions. Used for discovery planning, ideation, assumption mapping. Related: HMW statements, User story mapping

[... continue for ≥10 entries ...]

---

### Product Tools & Platforms

**T1. Mixpanel** (Product Analytics)  
Event tracking, funnel/cohort analysis, A/B testing, user segmentation. Freemium to Enterprise. 8K+ companies (Uber, Netflix). Updated Q3 2024 (AI insights). Integrates: Segment, Salesforce, Slack, Jira. PM use: Activation tracking, feature adoption, retention monitoring. https://mixpanel.com

**T2. ProductBoard** (Roadmapping & Prioritization)  
Feedback aggregation, prioritization matrix (value/effort), roadmap views, customer portal. Essentials $25/maker/mo to Enterprise. 6K+ teams (Microsoft, Zoom). Updated Q4 2024 (AI feedback analysis). Integrates: Jira, Slack, Salesforce, Intercom, Zendesk. PM use: Feedback synthesis, RICE scoring, stakeholder communication. https://www.productboard.com

**T3. Amplitude** (Product Analytics & Experimentation)  
Behavioral cohorts, retention/funnel analysis, A/B/n testing, predictive analytics. Freemium to Enterprise. 3.2K+ companies (PayPal, Ford). Updated Q3 2024 (AI insights, predictive playbooks). Integrates: Segment, Braze, Optimizely, Salesforce. PM use: North Star tracking, conversion optimization, impact analysis. https://amplitude.com

**T4. Dovetail** (User Research Repository)  
Auto transcription, tagging/theming, highlight reels, sentiment analysis, journey visualization. Freemium to Enterprise. 3K+ teams (Atlassian, Canva). Updated Q2 2024 (AI theme detection). Integrates: Zoom, Slack, Notion, Jira, UserTesting. PM use: Interview synthesis, JTBD mapping, discovery insights. https://dovetail.com

**T5. Miro** (Visual Collaboration)  
Infinite canvas, templates (story maps, journey maps, matrices), real-time collab, AI assistant. Freemium to Enterprise. 80M+ users (Dell, Cisco). Updated Q4 2024 (enhanced AI). Integrates: Jira, Slack, Teams, Zoom, Figma, Asana. PM use: Story mapping, OST workshops, roadmap planning, retrospectives. https://miro.com

[... continue for ≥5 entries ...]

---

### Authoritative Literature & Case Studies

**L1. Cagan, M. (2017). *Inspired* (2nd ed.). Wiley.**  
PM framework: discovery vs delivery, empowered teams. Foundational PM principles.

**L2. Olsen, D. (2015). *The Lean Product Playbook*. Wiley.**  
6-step process for product-market fit. Strategic planning, validation techniques.

**L3. Perri, M. (2018). *Escaping the Build Trap*. O'Reilly.**  
Outcomes over outputs, feature factory to outcome-driven culture. Organizational transformation.

**L4. Torres, T. (2021). *Continuous Discovery Habits*. Product Talk LLC.**  
Weekly customer touchpoints, opportunity solution trees. Discovery process design.

**L5. Patton, J. (2014). *User Story Mapping*. O'Reilly.**  
Story mapping by user journey (vs flat backlog). Roadmap planning, MVP scoping.

**L6. Klement, A. (2016). *When Coffee and Kale Compete*. Independent.**  
JTBD: functional/emotional/social jobs. Product positioning, competitive analysis.

[... continue for ≥6 entries ...]

---

### APA Style Source Citations

**A1. Cagan, M. (2017). *Inspired: How to create tech products customers love* (2nd ed.). Wiley. [EN]**

**A2. Olsen, D. (2015). *The lean product playbook: How to innovate with minimum viable products and rapid customer feedback*. Wiley. [EN]**

**A3. 俞军. (2020). *俞军产品方法论*. 中信出版社. [ZH]**  
(Yu, J. (2020). *Yu Jun's product methodology*. CITIC Press.)

**A4. Perri, M. (2018). *Escaping the build trap: How effective product management creates real value*. O'Reilly Media. [EN]**

**A5. Patton, J. (2014). *User story mapping: Discover the whole story, build the right product*. O'Reilly Media. [EN]**

**A6. Torres, T. (2021). *Continuous discovery habits: Discover products that create customer value and business value*. Product Talk LLC. [EN]**

**A7. Klement, A. (2016). *When coffee and kale compete: Become great at making products people will buy*. Independent. [EN]**

**A8. Ries, E. (2011). *The lean startup: How today's entrepreneurs use continuous innovation to create radically successful businesses*. Crown Business. [EN]**

**A9. McClure, D. (2007). Startup metrics for pirates: AARRR!. *500 Startups*. https://www.slideshare.net/dmc500hats/startup-metrics-for-pirates-long-version [EN]**

**A10. 梁宁. (2018). *产品思维30讲*. 得到App. [ZH]**  
(Liang, N. (2018). *30 lectures on product thinking*. Dedao App.)

**A11. Maurya, A. (2012). *Running lean: Iterate from plan A to a plan that works* (2nd ed.). O'Reilly Media. [EN]**

**A12. Eisenmann, T., Ries, E., & Dillard, S. (2012). Hypothesis-driven entrepreneurship: The lean startup. *Harvard Business School Entrepreneurial Management Case*, (812-095). [EN]**

**A13. Gothelf, J., & Seiden, J. (2016). *Lean UX: Designing great products with agile teams* (2nd ed.). O'Reilly Media. [EN]**

**A14. Bush, L., & Dunlap, K. (2023). *Product operations: How successful companies build better products at scale*. O'Reilly Media. [EN]**

**A15. 苏杰. (2019). *人人都是产品经理2.0*. 电子工业出版社. [ZH]**  
(Su, J. (2019). *Everyone is a product manager 2.0*. Publishing House of Electronics Industry.)

**A16. Kim, G. N. (2022). *Product leadership: How top product managers launch awesome products and build successful teams*. O'Reilly Media. [EN]**

[... continue for ≥12 entries with ~60% EN, ~30% ZH, ~10% other ...]

---

## Validation Report

Execute 11-step validation (Part I). Present results in table format upon completion. All checks must show PASS before submission.

---

## Example Scenario (Product Strategy & Prioritization)

### Scenario 1: Enterprise vs Mass Market Feature Conflict

**Difficulty:** Advanced | **Domain:** Product Strategy, Prioritization & Roadmapping

**Context:**

You're the PM for a B2B SaaS productivity tool with 50K SMB users (average $50/month) and 5 enterprise clients ($200K/year each, representing 40% of ARR). The top enterprise clients are requesting a sophisticated custom workflow builder that would take 6 months to build.

Your product vision focuses on simplicity and self-serve onboarding for the mass market. User research [Ref: L4] shows SMB users value ease of use and quick time-to-value [Ref: G8]. The custom workflow feature would add significant complexity to the UI and require professional services support.

Data from product analytics [Ref: T1] shows:
- SMB activation rate: 65% (use core feature within 7 days)
- SMB retention (90-day): 72%
- Enterprise retention: 95%
- Feature adoption: Top 3 features used by 80%+ of SMB users

Your CEO is concerned about enterprise churn risk. The engineering team says building the custom workflow would delay planned improvements to activation funnel by 2 quarters. Market analysis [Ref: A8] suggests your SMB TAM is 10× larger than enterprise, but enterprise deals are more predictable.

Sales argues the custom feature could unlock 10 more enterprise deals (potential $2M ARR). Product analytics [Ref: T3] shows a simplified onboarding flow could improve SMB activation by 15% (estimated +7.5K users, +$450K ARR).

**Task 1: Problem Diagnosis & Framework Application (8 pts)**

Apply RICE prioritization [Ref: G2] and JTBD framework [Ref: G3] to analyze both options. What is the core strategic tension, and which framework reveals it best?

**Expected Response:**
- Core tension: Short-term revenue protection vs long-term PMF and market expansion
- RICE analysis comparing both options with actual numbers
- JTBD discovery: What job are enterprise customers trying to hire the product for?
- Recognition that this is a strategy decision, not just a prioritization exercise
- Consideration of opportunity cost and product principles [Ref: L3]

**Grading:**
- Identifies strategic tension (not tactical): 2 pts
- Applies RICE with scenario data: 2 pts  
- Applies JTBD to uncover real needs: 2 pts
- Recognizes framework limitations: 2 pts

**Task 2: Prioritization & Decision Matrix (10 pts)**

Create a decision framework evaluating: (1) Enterprise custom workflow, (2) SMB activation improvements, (3) Generalized workflow builder, (4) Hybrid approach. Recommend a path with clear rationale.

**Expected Response:**

| Criterion | Enterprise Custom | SMB Activation | Generalized Builder | Hybrid (Services) | Weight |
|-----------|-------------------|----------------|---------------------|-------------------|--------|
| Revenue impact (12mo) | $2M (enterprise) | $450K (SMB growth) | $1M (both segments) | $1.5M | 25% |
| Strategic alignment | Low (custom) | High (vision-aligned) | High | Medium | 25% |
| PMF impact [Ref: G5] | Negative (complexity) | Positive (easier onboarding) | Positive | Neutral | 20% |
| Reach (users affected) | 5-15 enterprise | 50K+ SMB | All segments | Both | 15% |
| Execution risk | High (custom complexity) | Low (known problem) | High (scope) | Medium | 10% |
| Competitive moat | Low (replicable) | Medium | High | Medium | 5% |

Recommendation with rationale addressing CEO concerns and product principles.

**Grading:**
- Comprehensive criteria: 3 pts (revenue/strategy/PMF/reach/risk)
- Evaluates all options: 3 pts (not just binary choice)
- Proper weighting: 1 pt
- Clear recommendation: 2 pts (addresses stakeholder concerns)
- Considers hybrid/3rd options: 1 pt

**Task 3: Stakeholder Communication (6 pts)**

Draft a memo (≤300 words) to CEO and executive team explaining your recommendation.

**Expected Response:**
- Situation: Enterprise request, strategic tension, data summary
- Recommendation: Specific path forward with timeline
- Rationale: Decision criteria, scores, why this serves business best
- Risk mitigation: How to protect enterprise relationship
- Success metrics: How you'll measure if decision was right
- Next steps: Immediate actions, timeline, check-in points

**Grading:**
- Clarity and structure: 2 pts (exec-friendly format)
- Data-driven reasoning: 2 pts (metrics, not opinions)
- Addresses concerns: 1 pt (CEO's enterprise worry)
- Actionable next steps: 1 pt (clear path forward)

**Common Product Judgment Gaps:**
- Binary thinking (enterprise vs SMB) instead of exploring 3rd options
- Using frameworks mechanically without strategic context
- Ignoring opportunity costs (what we won't build)
- Failing to quantify impact with available data
- Not proposing experiments/validation before committing
- Overlooking execution feasibility and team velocity
- Missing stakeholder alignment needs

**Exemplary Approaches for Bonus:**
- Proposes discovery interviews to validate enterprise JTBD before deciding (+2 pts)
- Suggests A/B test or beta for generalized builder to de-risk (+2 pts)
- Includes monitoring plan with leading indicators of success/failure (+1 pt)
- Proactively designs mitigation strategy for enterprise churn risk (+1 pt)

---
