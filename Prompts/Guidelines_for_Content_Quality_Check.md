# Guidelines for Content Quality Check

**Purpose:** Improve content quality so readers (including future you and LLMs) can make reliable decisions with minimal clarification and rework.

**When to apply:** Use all guidelines for critical content that meets ≥1 criterion:
- Blocks decisions or actions
- Significant impact on outcomes
- Time-sensitive
- Multiple stakeholders
- Requires substantial effort to implement

Use selectively for other high-quality content.

**Expected impact:** ↓30-60% misunderstandings and clarifications, ↑60-80% decision quality.

## Guidelines (21 Total)

### Foundation: Define the Content's Purpose

**1. Context** [↓30-40% clarification]: Content explicitly states scope, constraints, assumptions, scale, timeline, domain, stakeholders, resources (where relevant). ❌ Bad: Only title and one line: "Design system". ✅ Good: Introduction states: "This content describes [the solution/approach/analysis] for [specific problem], covering [scope], targeting [scale/audience], to be completed within [timeline], involving [stakeholders], with [key constraints and assumptions]."

**2. Clarity** [↓25-35% ambiguity]: Content defines key terms and explains important relationships. ❌ Bad: Uses jargon or specialized terms without explanation. ✅ Good: Defines key terms explicitly, explains relationships between concepts, clarifies domain-specific terminology.

**3. Precision** [↓40-50% specification ambiguity]: Content uses quantified requirements with exact metrics, formulas, units where relevant. ❌ Bad: Vague qualifiers like "fast", "scalable", "high-quality", "soon". ✅ Good: Specific, measurable criteria with numbers, ranges, thresholds, or explicit quality level definitions.

**4. Relevance** [↓30-40% noise]: Content focuses on decision-critical aspects and pushes non-essential detail to appendices or references. ❌ Bad: Includes extensive background without clear connection to current decisions. ✅ Good: Focuses on information directly relevant to decisions or tasks; background context is brief or linked.

### Scope: What to Cover

**5. MECE** [↑40-50% completeness]: Sections are mutually exclusive and collectively exhaustive for the content's purpose. ❌ Bad: Topic coverage has gaps or overlaps. ✅ Good: Organizes content into distinct, non-overlapping sections that together cover all relevant aspects.

**6. Sufficiency** [↑35-45% comprehensiveness]: Content covers all necessary aspects for its purpose. ❌ Bad: Addresses only part of what's needed for complete understanding or action. ✅ Good: Covers all relevant dimensions (what, why, how, when, who, constraints, alternatives, risks, outcomes).

**7. Breadth** [↑30-40% perspective diversity]: Content reflects multiple stakeholder perspectives where appropriate. ❌ Bad: Addresses only one viewpoint or role. ✅ Good: Acknowledges and addresses concerns from all relevant stakeholders or perspectives.

**8. Depth** [↑25-35% thoroughness]: High-impact areas include implementation-level detail, not just high-level principles. ❌ Bad: States principles or recommendations without supporting detail. ✅ Good: Provides actionable specifics including options, trade-offs, parameters, concrete examples.

### Quality: Ensure Excellence

**9. Significance** [↓40-60% reading time]: Content highlights what matters most and deemphasizes low-impact details. ❌ Bad: Includes exhaustive lists of low-relevance items. ✅ Good: Focuses on critical elements; links to comprehensive references for completeness.

**10. Concision** [↓35-45% word count]: Content avoids redundancy and unnecessary filler. ❌ Bad: Repeats the same concept across multiple sections. ✅ Good: States each principle once, then references it; focuses on concrete details and examples in subsequent sections.

**11. Accuracy** [↓20-30% factual errors]: Factual statements are checked against up-to-date, authoritative sources. ❌ Bad: Makes claims without verification or uses outdated information. ✅ Good: Verifies facts against current, authoritative sources; flags version-specific or time-sensitive information.

**12. Credibility** [↑50-60% trust]: Important claims and recommendations cite primary, authoritative sources, preferably recent. ❌ Bad: "Best practices say..." with no reference. ✅ Good: Cites specific, authoritative sources (official documentation, peer-reviewed research, recognized standards, expert publications).

**13. Logic** [↓30-40% reasoning errors]: Arguments are coherent, consistent, and explicitly present trade-offs. ❌ Bad: Makes one-sided claims without acknowledging context or limitations. ✅ Good: Presents balanced analysis with clear reasoning, acknowledges trade-offs, specifies conditions where recommendations apply.

**14. Risk/Value** [↑60-80% decision quality]: Content compares ≥2 alternatives with costs, benefits, risks. ❌ Bad: Proposes single solution with no alternatives. ✅ Good: Compares multiple options with explicit costs, benefits, risks, and conditions for choosing each.

**15. Fairness** [↓40-50% bias]: Content presents balanced views, counterarguments, limitations. ❌ Bad: Advocates for one approach without addressing downsides. ✅ Good: Presents multiple perspectives, acknowledges limitations, includes counterarguments, specifies when approach is NOT recommended.

### Format: How to Present

**16. Structure** [↑30-40% scannability]: Content uses clear headings, sections, lists that make it easy to scan and act. ❌ Bad: Long, unstructured text blocks. ✅ Good: Organized with clear headings, bullet lists, comparison tables, visual aids; key information is scannable.

**17. Format** [↑35-45% readability]: Content follows consistent hierarchy and established conventions (e.g., H1 title, H2 sections, bullets, tables). ❌ Bad: Mixed heading levels and inconsistent formatting. ✅ Good: Uses predictable, consistent structure following established conventions.

### Validation: Ensure Correctness

**18. Evidence** [↑40-50% trust]: Citations include source details, recency, explicit uncertainty flags. ❌ Bad: "Studies show..." with no details. ✅ Good: Specific citations with source, date, page/section; explicitly flags estimates, assumptions, areas of uncertainty.

**19. Validation** [↓25-35% errors]: Author or reviewer performs structured self-review. ❌ Bad: Content published without verification. ✅ Good: Verifies calculations, checks for contradictions and inconsistencies, validates examples, confirms assumptions, explicitly flags open questions.

**20. Practicality** [↑50-60% implementation speed]: Content includes concrete steps, examples, guidance where appropriate. ❌ Bad: Generic or abstract recommendations only. ✅ Good: Includes actionable steps, specific examples, commands, formulas, checklists, decision trees where relevant.

**21. Success Criteria** [↑40-50% measurability]: Content defines measurable outcomes and how to validate them. ❌ Bad: Vague success criteria like "better performance". ✅ Good: Specific, measurable targets with baseline values, target values, measurement methods, validation approach.

## Quick Check (30s)

**Before publishing content (mandatory for critical content, recommended for others):**
- ☐ Self-contained (key context is present; references include brief summaries and working links)
- ☐ Context
- ☐ Clarity
- ☐ Precision
- ☐ Relevance
- ☐ MECE
- ☐ Sufficiency
- ☐ Breadth
- ☐ Depth
- ☐ Significance
- ☐ Concision
- ☐ Accuracy
- ☐ Credibility
- ☐ Logic
- ☐ Risk/Value
- ☐ Fairness
- ☐ Structure
- ☐ Format
- ☐ Evidence
- ☐ Validation
- ☐ Practicality
- ☐ Success Criteria

**Quality attributes:**
- Accurate
- Precise
- Cited
- Complete
- Actionable
- Consistent
- Relevant
- Balanced
- Appropriately recent (for time-sensitive topics)
- Testable/Verifiable

**Exclude or move to references:**
- Extensive background or history (unless essential for context)
- Pure theory (unless central to the topic)
- Edge cases with minimal impact and low severity
- Formal proofs (unless required)
- Trends without supporting data
- Speculation
- Content that only references other sources without summary or working link

**Always specify:** Key context (scope, constraints, assumptions, scale, timeline, domain, stakeholders, resources) so content stands alone and can be used reliably.

**Impact metrics:**
- ↓30-60% clarification cycles and misunderstandings (Context + Clarity)
- ↓25-50% ambiguity (Precision)
- ↑60-80% decision quality (Risk/Value)
- ↑35-50% completeness (MECE + Sufficiency)
- ↑30-45% scannability (Structure + Format)
- ↑50-60% implementation speed (Practicality)
