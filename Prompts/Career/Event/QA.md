# Event Analysis Framework

Generate evidence-based analyses of major incidents with RCA, multi-perspective evaluation, and transferable lessons.

## Scope & Requirements

**Deliverable**: 20–30 analyses (300–600w) across 6 domains (3–5 each) | Complexity: Basic:Int:Adv 20:40:40% (±5pp) | Languages: EN 50–70%, ZH 20–40%, Other 5–15%

**Per Analysis**: Timestamped timeline, RCA (proximate + systemic), quantified impact, multi-perspective (≥60% with 3+ views), actionable lessons, ≥3 citations (≥5 for 40%)

**Sources**: Primary ≥80% (incident reports, official statements, forensics, filings) | Contemporary ≥60% (±2yr) | All links functional/archived | Hierarchy: Official Reports/Post-mortems > Academic > Government > Industry > News > Commentary

## Terminology

**RCA**: Root Cause Analysis | **MTTR/MTBF**: Mean Time To Repair/Between Failures | **CVE**: Common Vulnerabilities & Exposures | **Zero-day**: Unpatched exploited vulnerability | **APT**: Advanced Persistent Threat | **DDoS**: Distributed Denial of Service | **Supply Chain Attack**: Compromise via trusted third-party | **Post-mortem**: After-action incident analysis | **SLA**: Service Level Agreement

## Domains (MECE)

| Domain | Scope | Examples |
|--------|-------|----------|
| **Security** | Breaches, attacks, vulnerabilities, leaks | Equifax 2017, SolarWinds 2020, Log4Shell 2021 |
| **Technical** | Outages, system failures, infrastructure | AWS S3 2017, Facebook BGP 2021, Knight Capital 2012 |
| **Market** | Crashes, bubbles, disruptions, shocks | 2008 Crisis, FTX 2022, GameStop 2021 |
| **Regulatory** | Policy changes, enforcement, compliance | GDPR 2018, Cambridge Analytica, Theranos |
| **Business** | Scandals, recalls, governance, fraud | Boeing 737 MAX, VW Dieselgate, Wells Fargo |
| **Technology** | Platform changes, deprecations, shifts | Flash EOL 2020, Twitter API, Apple ATT |

## Complexity Levels

| Level | % | Focus | Perspectives | Core Elements |
|-------|---|-------|--------------|---------------|
| **Basic** | 20±5 | Single cause, linear timeline | 1–2 | Timeline, 1 RCA, metrics, 3 citations, 1 lesson |
| **Intermediate** | 40±5 | Multiple causes, interconnected | 2–3 cross-domain | Detailed timeline, 2 RCA, tech+business, 5+ citations, 3 lessons |
| **Advanced** | 40±5 | Systemic causes, cascading | 4+ industry-wide | Full reconstruction, 3+ RCA, multi-impact, alternatives, 8+ citations, 5+ lessons, framework |

## Analysis Structure

1. **Overview** (2–3 sent): What, when, who affected [Ref: ID]
2. **Timeline** (5–10 points): Timestamped chronology, critical decisions [Ref: ID]
3. **Root Cause** (4–6 sent): Proximate, contributing, systemic with causal chains [Ref: ID]
4. **Technical** (3–5 sent): Mechanisms, vulnerabilities, failure modes [Ref: ID]
5. **Impact** (3–4 sent): Quantified financial, operational, reputational, regulatory [Ref: ID]
6. **Response** (Int/Adv, 3–4 sent): Actions, resolution, effectiveness [Ref: ID]
7. **Perspectives** (Int/Adv, 4–6 sent): ≥3 views (technical, business, regulatory, public) [Ref: ID]
8. **Lessons** (4–6 sent): Transferable insights, prevention, detection [Ref: ID]
9. **Alternatives** (Adv, 2–3 sent): Counterfactuals with estimated outcomes
10. **Takeaway**: Actionable, non-obvious, transferable, falsifiable

## Workflow

**1. References (Build First)**  
Glossary ≥15 | Tools ≥8 | Literature ≥8 | Citations ≥20 (≥4 types, max 20% single source, prioritize official)

**2. Event Selection**  
20–30 events across 6 domains (3–5 each) | Basic:Int:Adv 20:40:40 (±5pp) | Temporal/geographic diversity | Criteria: quantified impact, primary sources, transferable lessons, multi-perspective possible

**3. Analysis**  
Follow 10-part structure | Cite [Ref: ID] inline | Build causal chains | Quantify impacts | Checkpoint per 3: 300–600w, verified timeline, citations met, actionable lessons

**4. Artifacts**  
Per domain: ≥1 timeline + ≥1 impact table/diagram (chains, trees, cascades)

**5. Validation**  
18-check ALL PASS | FAIL → fix → re-validate ALL

## Quality Standards

**Verification**: ≥2 authoritative sources per claim | Flag uncertainty ("estimated," confidence levels) | Present competing narratives with citations | Note superseded findings

**Authoritative**: Peer-reviewed | Senior practitioner (10+ yrs) | Framework originator | Data-backed with methodology | Standards body

## Validation (ALL PASS Required)

| # | Check | Criteria |
|---|-------|----------|
| 1 | References | G≥15, T≥8, L≥8, A≥20 |
| 2 | Event counts | 20–30; Basic:Int:Adv 20:40:40 (±5pp) |
| 3 | Citations | ≥80% have ≥3; ≥40% have ≥5 |
| 4 | Language | EN 50–70%, ZH 20–40%, Other 5–15% |
| 5 | Contemporary | ≥60% from ±2yr |
| 6 | Diversity | ≥4 types; max 20% single |
| 7 | Links | 100% functional/archived |
| 8 | Cross-refs | All [Ref: ID] resolve |
| 9 | Word count | Sample 5: 300–600w |
| 10 | Takeaways | Actionable, non-obvious, transferable |
| 11 | Domain rigor | Each: ≥3 official + timeline |
| 12 | Timeline | Verified chronology + sources |
| 13 | RCA | ≥70% systemic + proximate |
| 14 | Fact-check | Sample 5: validated |
| 15 | Multi-perspective | ≥60% have 3+ views |
| 16 | Impact | ≥80% quantified metrics |
| 17 | Artifacts | Each domain: ≥1 timeline + ≥1 table |
| 18 | TOC | Functional section links |

**Result**: ✅ ALL PASS → deliver | ❌ FAIL → fix → re-validate ALL

## Multi-Perspective Framework

**Viewpoints** (≥3): Technical vs. Business | Prevention vs. Response | Individual vs. Systemic | Short-term vs. Long-term | Internal vs. External | Victim vs. Attacker

**Requirements**: 2+ causal interpretations [Ref: ID] | Alternatives with impact differences | Limitations noted | Conflicting narratives cited | Quantified uncertainties

**Quality**: ✅ "Supply chain attacks exploit trust > technical vulnerabilities; defense requires rethinking architectural assumptions + build verification" | ❌ "Security is important" (vague, obvious)

## Pitfalls & Solutions

| ❌ Avoid | ✅ Instead |
|----------|------------|
| Obscure events | Well-documented, multiple primary sources |
| Single domain | 6 domains, 3–5 each |
| Recent only | Temporal + geographic diversity |
| Vague timeline | Timestamped chronology + sources |
| Single cause | Proximate + contributing + systemic |
| Vague impact | Quantified metrics |
| Single perspective | ≥3 viewpoints |
| Generic citations | Specific [Ref: ID] to authoritative |
| Hindsight bias | Info available at decision time |
| Obvious lessons | Non-obvious, actionable, transferable |
| Low-quality sources | Primary reports, forensics, official |
| Broken links | Functional/archived URLs |

---

## Examples

### Basic (320w): Cloudflare BGP Route Leak (June 24, 2019)

**Complexity**: Basic | **Domain**: Technical Failures

**Overview**: Cloudflare suffered global outage affecting millions of websites for 30 minutes due to configuration error during routine maintenance [Ref: A1].

**Timeline**:  
- **13:42 UTC** - WAF rule deployment begins  
- **13:55** - CPU spike to 100% across global network  
- **14:00** - Services completely offline  
- **14:07** - Root cause identified (regex backtracking)  
- **14:12** - Rollback completed  
- **14:20** - Full service recovery [Ref: A1]

**Root Cause**: Regex optimization in WAF rules caused catastrophic backtracking on legitimate traffic patterns, consuming all CPU. Single problematic expression: `.*(?:.*=.*){  }` with repeated nested quantifiers [Ref: A1, G1]. **Proximate**: Untested regex deployed to production. **Systemic**: Insufficient load testing for adversarial edge cases; deployment without canary rollout or gradual traffic ramping [Ref: A1].

**Technical**: PCRE regex engine's exponential time complexity when processing crafted input patterns [Ref: A1]. CPU exhaustion prevented all request processing. Global synchronized deployment amplified impact across all data centers simultaneously [Ref: A1].

**Impact**: 50% of HTTP requests failed globally; ~27 minutes total downtime; millions of customer sites affected; no data breach or loss. Estimated $20M+ lost revenue across customer base [Ref: A2]. Significant reputational damage despite quick resolution.

**Response**: Immediate rollback within 12 minutes of identification. Post-incident: implemented ReDoS (Regular Expression Denial of Service) detection in CI/CD pipeline, mandatory canary deployments for configuration changes, CPU-based automated kill switches [Ref: A1].

**Lessons**:  
1. Regex complexity poses security and availability risk requiring automated analysis [Ref: A3]
2. Gradual rollouts essential even for "safe" configuration changes
3. Automated kill switches prevent single failures from cascading globally

**Takeaway**: Configuration changes carry equal risk to code deployments; testing must include adversarial inputs and performance limit validation, not just functional correctness.

---

### Intermediate (420w): Equifax Data Breach (March–July 2017)

**Complexity**: Intermediate | **Domain**: Security

**Overview**: Equifax exposed 147.9M people's sensitive data through unpatched Apache Struts vulnerability (CVE-2017-5638), compounded by multiple security control failures and 2-month delayed detection [Ref: A4, A5].

**Timeline**:  
- **Mar 7** - CVE-2017-5638 published; patch available  
- **Mar 8** - DHS alerts Equifax to vulnerability  
- **Mar 9** - Equifax patches "some systems," misses ACIS application  
- **Mar 10–May 13** - Attackers access systems undetected (66 days)  
- **May 13** - Suspicious traffic detected  
- **Jul 29** - Breach scope fully confirmed  
- **Sep 7** - Public disclosure (6 months post-initial compromise) [Ref: A4, A5]

**Root Cause**:  
**Proximate**: Unpatched CVE-2017-5638 allowing remote code execution via Content-Type header [Ref: A4].  
**Contributing**: (1) Expired SSL certificate blocked vulnerability scanning of ACIS [Ref: A6], (2) Network segmentation failures enabled lateral movement, (3) Plaintext credentials stored in files, (4) No file integrity monitoring detected data exfiltration.  
**Systemic**: Fragmented IT oversight across 50+ business units; no centralized patch management; expired asset inventory; security deprioritized culturally [Ref: A8].

**Technical**: Attackers exploited Jakarta Multipart parser deserialization flaw in Content-Type header, deployed web shells for persistence, extracted 48 databases via encrypted channels mimicking normal traffic patterns [Ref: A4, A5]. Lateral movement enabled by flat network architecture.

**Impact**: 147.9M consumer records (SSN, DOB, addresses); 209K credit cards; 182K dispute documents. $1.4B settlement; $1.5B+ total costs including forensics, remediation, legal [Ref: A6]. CEO, CIO, CSO resigned. Stock dropped 35% (-$5B market cap). Congressional hearings; criminal charges against executives trading on insider knowledge.

**Perspectives**:  
- **Technical**: Entirely preventable with basic security hygiene; defense-in-depth absent [Ref: A7]  
- **Business**: Culture prioritized revenue growth over security investment; security seen as cost center [Ref: A8]  
- **Regulatory**: Catalyzed stricter data breach notification laws; increased FTC/CFPB oversight [Ref: A9]  
- **Public**: Widespread trust erosion in credit bureaus; calls for regulation of credit reporting industry [Ref: A10]

**Response**: 66 days to detect; 6 additional weeks to disclose publicly. Launched TrustedID monitoring (criticized for arbitration clauses). Implemented full-disk encryption, micro-segmentation, 24/7 SOC monitoring [Ref: A6].

**Lessons**:  
1. Patch management is existential for companies holding sensitive data  
2. Defense-in-depth (segmentation, encryption, monitoring) prevents total compromise from single vulnerability  
3. Monitoring must detect lateral movement and anomalous data access, not just perimeter breaches  
4. Timely disclosure is both ethical imperative and legal requirement

**Takeaway**: Security incidents rarely stem from single cause; organizational culture and basic security hygiene matter more than sophisticated defenses when fundamentals are absent.

---

### Advanced (580w): SolarWinds Supply Chain Attack (March–Dec 2020)

**Complexity**: Advanced | **Domain**: Security, Business

**Overview**: Russian APT29 (Cozy Bear) compromised SolarWinds Orion platform via malicious code injection into build process, affecting 18,000+ organizations including nine U.S. federal agencies, demonstrating sophisticated supply chain attack at unprecedented scale [Ref: A11, A12, A13].

**Timeline**:  
- **Sep 2019** - Target reconnaissance begins  
- **Oct 2019–Feb 2020** - C2 infrastructure preparation  
- **Mar 2020** - SUNBURST backdoor inserted into Orion source  
- **Mar 26, 2020** - Malicious update 2019.4 HF 5 signed and released  
- **Apr–May 2020** - Selective implant activation (~100 of 18,000 targets)  
- **Jun–Nov 2020** - Sustained stealthy exfiltration from high-value targets  
- **Dec 8, 2020** - FireEye discloses own breach, discovers SUNBURST  
- **Dec 13, 2020** - SolarWinds confirms compromise  
- **Dec 2020–Jan 2021** - Industry-wide emergency response and investigation  
- **2021–ongoing** - Attribution confirmed, forensics, long-term remediation [Ref: A11, A12]

**Root Cause**:  
**Attack Chain**: (1) Compromise build environment access controls, (2) Inject SUNBURST backdoor into Orion platform DLLs, (3) Sign with legitimate SolarWinds certificate, (4) Deploy via trusted automatic update mechanism, (5) Selectively activate implants (0.2% of victims), (6) Deploy second-stage TEARDROP/RAINDROP for high-value targets, (7) Establish C2 via legitimate cloud infrastructure (GoDaddy, AWS) [Ref: A12, A13].  
**Proximate**: Weak build system access controls; insufficient code review for build output differences; lack of build integrity verification [Ref: A14].  
**Systemic**: (1) Software supply chain fundamentally lacks verifiable trust mechanisms, (2) Security monitoring focuses on perimeter, not trusted software behavior, (3) Attribution delays enabled 9+ months undetected access, (4) Interconnected IT infrastructure creates systemic single points of failure.

**Technical**: SUNBURST used domain generation algorithm (DGA) for C2 via DNS queries, mimicked normal Orion "Orion Improvement Program" traffic patterns, delayed execution 12–14 days to evade sandboxes, employed blocklisting of security researcher IP ranges and forensic tools. Code injection via MSBuild project configuration modification [Ref: A12, A15]. Second-stage focused on <100 high-value targets with custom tooling avoiding automated detection.

**Impact**:  
- **Direct**: 18,000+ organizations installed backdoor; ~100 actively exploited with sustained access  
- **Government**: Nine federal agencies (Treasury, State, Commerce, Homeland Security, DOE, DOD, Justice, NIH, NNSA) [Ref: A16]  
- **Private Sector**: Microsoft, FireEye, Cisco, Intel, Deloitte, VMware  
- **Financial**: SolarWinds $18M immediate costs + ongoing litigation; industry-wide estimated $100B+ remediation [Ref: A17]  
- **Strategic**: Exposed critical U.S. cyber defense capability gaps; compromised sensitive communications; prompted Executive Order 14028 on cybersecurity

**Perspectives**:  
- **Technical**: Highlighted systematic neglect of build system security as critical attack surface [Ref: A14]  
- **Intelligence**: Attribution took months despite advanced capabilities; Russia denied involvement; exposed intelligence community's detection gaps [Ref: A16]  
- **Regulatory**: Accelerated zero-trust architecture mandates, software bill of materials (SBOM) requirements, secure software development attestations [Ref: A18]  
- **Industry**: Fundamental trust crisis in software supply chain; recognition that perimeter security insufficient [Ref: A19]  
- **Geopolitical**: Cyber espionage elevated to tier-one national security threat; diplomatic sanctions imposed

**Response**: Nine months undetected; detection by victim (FireEye) not SolarWinds monitoring. Massive coordinated industry response: emergency patches, forensic investigations, infrastructure hardening. Government response: diplomatic sanctions, Executive Order 14028, CISA emergency directives, increased funding for cyber defense [Ref: A18].

**Alternative Scenarios**:  
- **If detected at build stage**: Attack prevented entirely; estimated $100B+ damage avoided  
- **If SBOM mandated**: Faster anomaly detection via dependency/hash verification  
- **If zero-trust architecture implemented**: Limited lateral movement; reduced high-value target compromise  
- **If behavioral monitoring of trusted software**: Earlier detection of anomalous SUNBURST C2 patterns

**Preventive Framework**:  
1. **Build System Isolation**: Air-gapped build environments, hardware-backed code signing, comprehensive build audit logging [Ref: A14]  
2. **Code Signing Integrity**: Hardware security modules (HSMs) for private keys, multi-party approval for signing  
3. **Transparency**: Software Bill of Materials (SBOM), reproducible builds, cryptographic build attestations  
4. **Behavioral Analytics**: Monitor trusted software for anomalous behavior (network, file, process patterns)  
5. **Zero-Trust Architecture**: Micro-segmentation, least-privilege access, continuous authentication  
6. **Threat Intelligence Sharing**: Industry-government collaboration, rapid IOC distribution

**Lessons**:  
1. Trust is the fundamental vulnerability in modern software supply chains; verification must replace implicit trust  
2. Sophisticated state actors target weakest infrastructure link (build systems), not strongest (perimeter defenses)  
3. Detection requires monitoring behavior of trusted processes, not just untrusted sources  
4. Response coordination is critical for systemic threats affecting entire industries  
5. Regulatory frameworks persistently lag technical reality; proactive security investment essential  
6. Supply chain security requires rethinking software development and distribution architecture

**Takeaway**: Modern cyber warfare exploits trust relationships rather than purely technical vulnerabilities; supply chain security requires paradigm shift from perimeter defense to cryptographic verification at every layer, with transparency and behavioral monitoring of even trusted components.

## Output Format

```markdown
# Event Analysis Compendium

## TOC
1. Overview & Methodology
2. Event Distribution (table: domain, dates, count, complexity split, key sources)
3. Domain Analyses (3.1-3.6: Security, Technical, Market, Regulatory, Business, Technology)
4. References (4.1 Glossary ≥15 | 4.2 Tools ≥8 | 4.3 Literature ≥8 | 4.4 Citations ≥20)
5. Validation Report (18-check table)

## Per Event
**Complexity** | **Domain** | **Impact** | **Takeaway**  
**Overview** [Ref] | **Timeline** (5–10) [Ref] | **Root Cause** [Ref] | **Technical** [Ref] | **Impact** [Ref]  
**Response** (Int/Adv) [Ref] | **Perspectives** (Int/Adv, ≥3) [Ref] | **Lessons** [Ref] | **Alternatives** (Adv) | **Artifacts**

## References Format
**G#**: Term | Definition | Detection/Prevention  
**T#**: Name | Function | Deployment | Limitations | URL  
**L#**: Author (Year) | Title | Publisher | Frameworks  
**A#**: Full APA 7th | Type | [Lang] | URL/Archive
```

## Usage

1. **References First**: G≥15, T≥8, L≥8, A≥20 (official, contemporary)
2. **Select**: 20–30 events, 6 domains, Basic:Int:Adv 20:40:40 (±5pp), diverse
3. **Analyze**: 10-part structure, cite [Ref: ID], causal chains, quantify
4. **Artifacts**: ≥1 timeline + ≥1 table per domain
5. **Validate**: 18-check ALL PASS → deliver

**Success**: All checks pass | Primary sources | Timelines + multi-RCA + quantified | Multi-perspective ≥60% | Lessons actionable/transferable/non-obvious | Authoritative/diverse/contemporary refs | Functional links | No broken refs
