# Extract Debug Cards

1. Q: A CFO models 12-month runway assuming CAC will increase 10-15% due to AI startup competition. The report states AI startups captured 52.5% of VC funding with competitors likely to outspend on customer acquisition. What is wrong with the 10-15% assumption and how should it be corrected?
   A: **Issue**: The 10-15% assumption significantly underestimates competitive pressure. The report explicitly states CAC may increase 20-40%, not 10-15%. **Impact**: Underestimating CAC increase by half could lead to runway miscalculation of 2-4 months, causing emergency fundraising or layoffs. **Correction**: Use 20-40% CAC increase assumption (or model three scenarios: 20%, 30%, 40%) and include sensitivity analysis showing cash exhaustion dates at each level. Conservative planning would use 40% for Formation-stage startups with <12mo runway.

1. Q: An engineering team plans a staged rollout of critical RCE vulnerability patches: dev (Day 1) → staging (Day 5) → low-priority prod (Day 12) → high-priority prod (Day 20). What is wrong with this timeline and how should it be corrected?
   A: **Issue**: The 20-day total timeline for completing patches violates the report's explicit recommendation of patching "within 2 weeks" (14 days). Critical RCE vulnerabilities expose production systems to immediate compromise risk. **Impact**: Extending to 20 days increases exploitation window by 43%, particularly risky for high-priority production systems patched last. Potential data exfiltration, service disruption, regulatory penalties. **Correction**: Compress timeline: dev (Day 1) → staging (Day 3-4) → low-priority prod (Day 7-8) → high-priority prod (Day 12-14), with 24-hour monitoring between stages. For mission-critical systems, consider Option 3 from report: temporary workarounds (network segmentation/WAF rules) immediately while testing patches in parallel.

1. Q: A product team decides to migrate all features to GPT-5.1 immediately after reading that it "significantly outperforms" GPT-4 in reasoning tasks. They allocate 1 sprint for full migration and plan to deploy to production without A/B testing. What are the errors in this approach?
   A: **Issue 1**: Report recommends 2 sprints for evaluation + testing, not immediate full migration. Team skipped the evaluation framework and benchmarking phase. **Issue 2**: No A/B testing ignores the report's explicit recommendation to "monitor customer NPS/satisfaction scores bi-weekly during migration" with success metric of "no >5% NPS degradation." **Issue 3**: Migrating all features ignores cost consideration—GPT-5.1 is 20-30% more expensive. Team didn't evaluate cost-performance trade-offs or consider tiered approach. **Impact**: Risk of integration bugs, UX degradation, unexpected cost overruns (potentially 20-30% increase in inference costs), no rollback plan. **Correction**: Follow report's recommended approach: (1) Define top 3 reasoning-critical use cases, (2) Allocate 2 sprints for parallel benchmarks with 20-30 test cases from production data, (3) Migrate highest-value use case first with A/B testing, (4) Monitor NPS bi-weekly, (5) Stage additional migrations only if success criteria met.

1. Q: A marketing team repositions product messaging to emphasize "autonomous AI agents" despite having only basic workflow automation and API integrations. They claim this aligns with the 78% enterprise adoption finding. What is problematic about this positioning?
   A: **Issue**: The report defines agentic AI as "autonomous task execution, tool use, workflow orchestration" and recommends messaging pivot "if product already has 2+ agentic capabilities." Basic workflow automation doesn't meet this standard. Report explicitly recommends "Option 3 - Product-First Approach" (build features before repositioning) for products where "features non-existent." **Impact**: Creates customer expectations mismatch, risks reputation damage when buyers discover limited autonomy, potential false advertising concerns. May confuse existing customers (per report: "Risk: confuses existing customers if execution is inconsistent"). **Correction**: Follow report's Option 2 (Gradual Messaging Evolution): A/B test agentic messaging in new campaigns while maintaining legacy positioning, or invest 3-6 months in product development to build genuine agentic capabilities before full repositioning. Alternatively, use report's "Human-in-Loop Agent" framing to accurately describe supervised automation capabilities without overpromising autonomy.

1. Q: A CTO reads that the EU Digital Omnibus may delay high-risk AI system rules by 16 months and immediately cancels all AI Act compliance work scheduled for 2026, redirecting resources to product development. The company operates healthcare AI tools in the EU market. What is wrong with this decision?
   A: **Issue**: Report explicitly states: "Organizations with high-risk AI systems gain extended compliance runway but face continued regulatory uncertainty" and recommends "Option 1 - Maintain Original Timeline (Recommended for high-risk exposure)" specifically for regulated industries including healthcare. The decision contradicts this guidance. **Impact**: Healthcare AI qualifies as high-risk under AI Act Annex III. Canceling compliance work creates massive debt if delay doesn't materialize or if interim enforcement occurs. Healthcare is heavily regulated—GDPR and sector-specific regulations still apply regardless of AI Act timeline. **Correction**: Follow report's Option 1: Continue August 2026 compliance prep despite potential delay. Rationale from report: "Readiness regardless of final timeline, competitive advantage if standards tighten." For healthcare specifically, maintain foundational work (model documentation, data lineage, explainability) that applies regardless of final timeline. This positions the company for readiness and demonstrates regulatory good faith.

1. Q: A CFO allocates exactly $68K/month for AI infrastructure in 2026 based on the report's projection that current $50K/month could increase to $68K (+36% growth). They present this as a "data-driven" budget. What is insufficient about this approach?
   A: **Issue 1**: Report recommends "Option 3 - Hybrid Model: Reforecast +20%, initiate optimization workstream" (not just accepting +36% as inevitable) or modeling three scenarios (+20%, +30%, +40%) with trade-offs. Single-point estimate ignores uncertainty and optimization potential. **Issue 2**: The 36% is industry average—report explicitly warns this includes "organizations with vastly different AI usage patterns" and that "individual company's cost drivers may differ significantly." Blindly applying average commits aggregation fallacy. **Issue 3**: No quarterly review gates or optimization plan—report recommends "quarterly review gates" and identifying "top 3 optimization opportunities" to achieve "15-20% cost efficiency gain." **Impact**: Budget may be too high (wasted allocation) or too low (mid-year scramble), no flexibility for changing usage patterns, missed optimization opportunities. **Correction**: Model three scenarios tied to feature roadmap (base case +20%, moderate +30%, aggressive +40%), implement cost tracking dashboard by feature/user cohort, prioritize top 3 optimization opportunities (prompt caching, model downgrading for low-value requests, usage-based throttling), establish monthly AI cost review with Engineering, include quarterly decision gates to reallocate based on actual burn rate.
