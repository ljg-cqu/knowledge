# Extract Decision Questions

1. Q: Your AI startup has 8 months of runway remaining. AI startups captured 52.5% of global VC ($192.7B YTD), creating intense competition. You can either (A) accelerate fundraising now with strong technical traction but limited revenue, or (B) delay 4 months to reach profitability milestones but risk competitor market capture. What would you do and why?
   A: **Decision Framework**: (1) **Assess competitive timing**: If 3+ direct competitors recently raised Series A, market window may be closing—favor Option A. (2) **Evaluate burn multiple**: If path to profitability requires <$100K additional spend, favor Option B for better valuation. (3) **Investor pipeline strength**: If CEO has warm introductions to 15-20 target VCs, Option A risk is lower. (4) **Market velocity**: In 52.5% VC concentration environment, capital is available but competitive—technical differentiation + proprietary data moats are critical. (5) **Recommendation**: Choose Option A if (a) differentiation story is compelling, (b) TAM >$1B, (c) technical risk is largely retired. Choose Option B only if cash-flow positive within 4 months is highly certain (>80% confidence). **Action**: If Option A, execute CFO's 12-month cash runway model with 20-40% CAC increase, draft differentiated positioning deck immediately, target 5 partner meetings within 2 weeks.

1. Q: You operate AI inference infrastructure affected by CVE-2025-30165 (vLLM) and CVE-2025-23254 (NVIDIA TensorRT-LLM). Your infrastructure team proposes waiting 3 weeks for the next scheduled maintenance window to patch thoroughly. Your CISO wants emergency patching within 48 hours with staged rollout. How do you decide between stability and security urgency?
   A: **Risk Assessment Model**: (1) **Exposure surface**: If services are internet-facing with public API endpoints, exploitation probability is HIGH—favor 48-hour emergency patch. If air-gapped or internal-only, 3-week timeline is more defensible. (2) **Data sensitivity**: Customer PII, model weights, or proprietary data exposure → Emergency patching mandatory. (3) **Downtime tolerance**: Calculate revenue impact of 1-2 hours downtime per service vs potential breach cost (GDPR penalties: up to 4% global revenue). (4) **Testing capacity**: If you have blue-green deployment capability + comprehensive test suite, 48-72 hour timeline is achievable with acceptable risk. **Recommendation**: Default to emergency patching (Option 1) unless all conditions met: (a) no internet-facing exposure, (b) network segmentation already implemented, (c) no customer data in scope. **Execution**: Staged rollout: dev → staging (24hr monitor) → 5% prod canary (24hr) → full prod, with automated rollback triggers for error rate >2x baseline or latency >1.5x baseline.

1. Q: Your product roadmap includes migrating from GPT-4 to GPT-5.1 (20-30% cost increase) or Gemini 3 (pricing TBD). Your product has 60% content generation use cases and 40% complex reasoning use cases. How do you prioritize migration investment given cost and competitive considerations?
   A: **Use Case Segmentation**: (1) **Complex reasoning (40%)**: This is where GPT-5.1/Gemini 3 provide clear advantage—prioritize migration here first. Run 2-sprint benchmark on production test cases to quantify accuracy improvement. (2) **Content generation (60%)**: Diminishing returns for new models—maintain GPT-4 or consider cheaper alternatives (Claude Sonnet, GPT-4 Turbo). (3) **Cost-Performance Analysis**: Calculate blended cost impact: If reasoning use cases are 30% of inference volume but 40% of value, migrating only those to GPT-5.1 results in ~6-9% total cost increase (30% of 20-30%), not full 20-30%. (4) **Competitive Moat**: If reasoning quality is primary differentiation vs competitors, migration is strategic imperative. If UX/integration is moat, deprioritize. **Recommendation**: Hybrid tiering approach—GPT-5.1 for reasoning tasks, GPT-4 for content generation. Implement routing logic based on task classification. Monitor NPS specifically for reasoning-heavy users. Consider premium tier option (+20-30% pricing) with best-in-class models to pass costs to value-seeking customers.

1. Q: Your CRO wants to rebrand entire GTM messaging around "agentic AI" based on 78% enterprise adoption and the Anthropic/OpenAI market shift. Your product has workflow automation and API integrations but no autonomous task execution. You can invest 3 months building agentic features or reposition messaging immediately. What's your decision and rationale?
   A: **Capability Audit**: (1) **Current state**: Workflow automation + API integrations = 1.5 out of 3 agentic capabilities (autonomous execution, tool use, orchestration). This is borderline. (2) **Market timing**: 78% adoption suggests late-stage—repositioning delay may cost deals. (3) **Execution risk**: Messaging without substance risks customer disappointment and sales credibility damage. **Decision Matrix**: (a) If you have tool-use capability (API integrations that AI calls autonomously), you can truthfully claim "Agent-Ready Platform"—favor immediate positioning with Option 3 (Ecosystem Integration). (b) If workflow automation requires human approval at every step, you lack autonomy—favor 3-month product development before messaging shift. **Recommendation**: Hybrid approach—immediate repositioning as "Human-in-Loop Agents" or "Supervised Agentic Workflows" (technically accurate) while allocating 2 sprints to remove 2-3 manual approval gates in highest-value workflows. This creates 60-day path to genuine autonomy for key use cases. Launch agentic messaging campaign targeting design partners willing to co-develop advanced features. **KPI**: 30% of new pipeline tagged "agentic positioning" with +15% win rate improvement within 90 days.

1. Q: Your FY2026 AI infrastructure budget is currently planned at +15% growth ($57.5K/month from $50K). Industry average is +36% ($68K/month). Your CFO wants to increase budget to $68K. Your CTO wants to maintain $57.5K and invest in optimization. How do you allocate resources between budget increase and efficiency investment?
   A: **Cost Driver Analysis**: (1) **Categorize spend**: Inference API calls, training/fine-tuning, vector DB storage, model hosting. Identify top 10 cost drivers by feature. (2) **Optimization potential**: Prompt caching (10-15% savings), model downgrading for low-value requests (15-20% savings), usage-based throttling (5-10% savings). Combined potential: 20-30% efficiency gain. (3) **Growth projection**: Model three scenarios tied to product roadmap—conservative (+20%), moderate (+30%), aggressive (+40%)—rather than accepting +36% as inevitable. **Decision Framework**: Option 3 (Hybrid)—Reforecast at +25% ($62.5K/month, midpoint between CFO and CTO), allocate 1 engineer for 2 months to implement top 3 optimizations (cost: ~$30K, potential annual savings: $90K-$180K). Establish monthly cost review with Engineering and quarterly decision gates to adjust. **ROI Calculation**: 2 months engineering effort to achieve 15-20% cost efficiency gains pays for itself within 4-6 months. At $62.5K/month baseline, 20% savings = $12.5K/month = $150K annually. **Execution**: Implement cost tracking dashboard (cost per feature, per user cohort) immediately, prioritize prompt caching for high-frequency endpoints first (fastest ROI), monitor burn rate monthly and adjust budget at Q2 review based on actual vs projected.

1. Q: The EU Digital Omnibus may delay high-risk AI system compliance by 16 months (Aug 2026 → Dec 2027). Your company operates AI-powered credit scoring in the EU with compliance budgeted at $500K for 2026. You can (A) maintain compliance timeline, (B) delay compliance work and accelerate feature development, or (C) opportunistically expand high-risk features during extended grace period. What's your strategic decision?
   A: **Risk Assessment**: (1) **Industry context**: Credit scoring is explicitly high-risk under AI Act Annex III—regulatory scrutiny is HIGH. Financial services face additional sector regulations (Basel III, consumer protection laws). (2) **Uncertainty evaluation**: "May delay... depending on availability of support tools and standards" = Uncertain. Delay is not guaranteed. (3) **Opportunity cost**: $500K redirected to features could deliver 2-3 major capabilities, but creates compliance debt if delay doesn't materialize. **Decision Framework**: For financial services / high-risk AI in regulated industries, Option A (Maintain Timeline) is strongly recommended. Rationale: (a) Regulatory good faith—demonstrating proactive compliance reduces enforcement risk even if timeline shifts. (b) Competitive advantage—if standards tighten or timeline doesn't delay, compliant companies win enterprise deals. (c) Foundational work (model documentation, data lineage, explainability) improves product quality regardless. **Execution**: Continue planned compliance timeline but optimize for dual-use work—invest in explainability features that serve both compliance and customer trust. Allocate 20% of compliance budget ($100K) to monitor EC standards development and industry consultation. Avoid Option C (Opportunistic Expansion) entirely—credit scoring is high-litigation-risk domain; aggressive feature expansion without compliance readiness invites regulatory backlash. **Monitor**: Quarterly reassessment based on EC standards publication and peer enforcement actions.
